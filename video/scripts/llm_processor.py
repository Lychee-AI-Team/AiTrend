#!/usr/bin/env python3
"""
Gemini LLM è§†é¢‘è„šæœ¬ç”Ÿæˆå™¨
å¤ç”¨ AiTrend çš„ Gemini é…ç½®
"""

import json
import os
import sys
import urllib.request
import urllib.error
from typing import Dict, Any
from datetime import datetime

# æ·»åŠ  AiTrend è·¯å¾„
sys.path.insert(0, '/home/ubuntu/.openclaw/workspace/AiTrend')


class GeminiLLMClient:
    """Gemini LLM å®¢æˆ·ç«¯ï¼ˆä¸ AiTrend å®ç°ä¸€è‡´ï¼‰"""
    
    def __init__(self, model_name: str = None, api_key: str = None):
        """
        åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
            api_key: API Keyï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼ˆä¸ AiTrend ä¸€è‡´ï¼‰
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        self.model_name = model_name or os.getenv('GEMINI_MODEL', 'gemini-2.0-flash')
        
        if not self.api_key:
            raise RuntimeError("âŒ GEMINI_API_KEY not set. è¯·ç¡®ä¿ç¯å¢ƒå˜é‡å·²æ­£ç¡®å¯¼å‡º")
        
        # Gemini API URL
        self.api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.model_name}:generateContent"
    
    def generate(self, prompt: str, temperature: float = 0.7, max_tokens: int = 4000) -> str:
        """
        è°ƒç”¨ Gemini API ç”Ÿæˆå†…å®¹
        
        Args:
            prompt: æç¤ºè¯
            temperature: æ¸©åº¦ï¼ˆåˆ›é€ æ€§ï¼‰
            max_tokens: æœ€å¤§è¾“å‡ºé•¿åº¦
            
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
        """
        # æ„å»ºè¯·æ±‚ä½“
        payload = json.dumps({
            "contents": [
                {
                    "role": "user",
                    "parts": [{"text": prompt}]
                }
            ],
            "generationConfig": {
                "temperature": temperature,
                "maxOutputTokens": max_tokens,
                "topP": 0.95,
                "topK": 40
            }
        }, ensure_ascii=False).encode('utf-8')
        
        # æ„å»ºè¯·æ±‚
        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": self.api_key
        }
        
        req = urllib.request.Request(
            self.api_url,
            data=payload,
            headers=headers,
            method="POST"
        )
        
        try:
            # å‘é€è¯·æ±‚
            with urllib.request.urlopen(req, timeout=60) as response:
                result = json.loads(response.read().decode('utf-8'))
                
                # æå–ç”Ÿæˆçš„æ–‡æœ¬
                if "candidates" in result and len(result["candidates"]) > 0:
                    text = result["candidates"][0]["content"]["parts"][0]["text"]
                    return text
                else:
                    raise Exception("Gemini API è¿”å›ç©ºç»“æœ")
                    
        except urllib.error.HTTPError as e:
            error_body = e.read().decode()
            raise Exception(f"Gemini API é”™è¯¯: {e.code} - {error_body}")
    
    def generate_video_script(self, hotspots_data: Dict) -> Dict:
        """
        ç”Ÿæˆè§†é¢‘è„šæœ¬ï¼ˆä¸“ç”¨æ–¹æ³•ï¼‰
        
        Args:
            hotspots_data: çƒ­ç‚¹æ•°æ®ï¼ˆç²¾é€‰åçš„5-10æ¡ï¼‰
            
        Returns:
            è§†é¢‘è„šæœ¬ JSON
        """
        # æ„å»º Prompt
        prompt = self._build_script_prompt(hotspots_data)
        
        print(f"ğŸ¤– è°ƒç”¨ Gemini ({self.model_name}) ç”Ÿæˆè„šæœ¬...")
        
        # è°ƒç”¨ Gemini
        response = self.generate(
            prompt=prompt,
            temperature=0.7,
            max_tokens=4000
        )
        
        # è§£æ JSON å“åº”
        try:
            script = json.loads(response)
            print(f"âœ… è„šæœ¬ç”ŸæˆæˆåŠŸ")
            return script
        except json.JSONDecodeError:
            # å¦‚æœè¿”å›çš„ä¸æ˜¯æ ‡å‡† JSONï¼Œå°è¯•æå– JSON éƒ¨åˆ†
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                try:
                    script = json.loads(json_match.group())
                    print(f"âœ… è„šæœ¬ç”ŸæˆæˆåŠŸï¼ˆä»æ–‡æœ¬ä¸­æå–ï¼‰")
                    return script
                except:
                    pass
            
            # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬åŒ…è£…
            print(f"âš ï¸  è¿”å›æ ¼å¼éæ ‡å‡† JSONï¼ŒåŒ…è£…ä¸ºæ–‡æœ¬")
            return {
                "raw_text": response,
                "parse_error": True
            }
    
    def _build_script_prompt(self, hotspots_data: Dict) -> str:
        """æ„å»ºè§†é¢‘è„šæœ¬ç”Ÿæˆ Prompt"""
        
        hotspots = hotspots_data.get('hotspots', [])
        date = hotspots_data.get('date', datetime.now().strftime('%Y-%m-%d'))
        
        # æ„å»ºçƒ­ç‚¹æ‘˜è¦
        hotspots_summary = []
        for item in hotspots:
            summary = {
                'rank': item.get('rank', 0),
                'title': item.get('title', ''),
                'summary': item.get('summary', ''),
                'source': item.get('source_origin', 'unknown'),
                'heat_score': item.get('heat_score', 0)
            }
            hotspots_summary.append(summary)
        
        hotspots_json = json.dumps(hotspots_summary, ensure_ascii=False, indent=2)
        
        return f"""ä½ æ˜¯ä¸“ä¸šAIæ–°é—»è§†é¢‘ç¼–è¾‘ï¼Œè¯·å°†ä»¥ä¸‹çƒ­ç‚¹æ•°æ®è½¬åŒ–ä¸º3åˆ†é’Ÿè§†é¢‘æ’­æŠ¥è„šæœ¬ã€‚

æ—¥æœŸï¼š{date}
çƒ­ç‚¹æ•°æ®ï¼š
{hotspots_json}

è¾“å‡ºè¦æ±‚ï¼š
1. openingï¼ˆå¼€åœºï¼‰ï¼š10-15ç§’ï¼Œä»Šæ—¥æ¦‚è§ˆï¼Œå¸å¼•è§‚ä¼—
   - åŒ…å«æ—¥æœŸå’Œæ€»è§ˆ
   - è¯­æ°”çƒ­æƒ…ä¸“ä¸š
   
2. detailed_hotspotsï¼ˆè¯¦ç»†æ’­æŠ¥ï¼‰ï¼šå‰3æ¡çƒ­ç‚¹ï¼Œå„40-45ç§’
   - æ¯æ¡åŒ…å«ï¼š
     - title: ä¼˜åŒ–åçš„å£è¯­åŒ–æ ‡é¢˜
     - script: è¯¦ç»†æ’­æŠ¥è„šæœ¬ï¼ˆ3-4å¥è¯ï¼Œå£è¯­åŒ–ï¼‰
     - key_point: æ ¸å¿ƒè§‚ç‚¹/æ•°æ®
     - source: ä¿¡æ¯æ¥æº
     - duration: "45ç§’"
   
3. quick_hotspotsï¼ˆå¿«é€Ÿæ’­æŠ¥ï¼‰ï¼šå‰©ä½™çƒ­ç‚¹ï¼Œå„15-20ç§’ï¼Œä¸€å¥è¯æ‘˜è¦
   - æ¯æ¡åŒ…å«ï¼š
     - title: çƒ­ç‚¹æ ‡é¢˜
     - script: ä¸€å¥è¯æ‘˜è¦
     - duration: "20ç§’"
   
4. closingï¼ˆç»“å°¾ï¼‰ï¼š5-10ç§’ï¼Œæ€»ç»“+å¼•å¯¼å…³æ³¨
   - ç®€æ´æœ‰åŠ›
   - å¼•å¯¼å…³æ³¨

é£æ ¼è¦æ±‚ï¼š
- å£è¯­åŒ–ã€è‡ªç„¶ã€åƒçœŸäººä¸»æ’­
- ä¸“ä¸šä½†ä¸ç”Ÿç¡¬
- æ¯æ®µéƒ½æœ‰é’©å­ï¼Œä¿æŒè§‚ä¼—æ³¨æ„åŠ›
- 100%ä¸­æ–‡è¾“å‡º
- é¿å…è¿‡äºå­¦æœ¯åŒ–çš„è¡¨è¾¾
- é€‚å½“ä½¿ç”¨å£è¯­è¿æ¥è¯ï¼ˆ"é‚£ä¹ˆ"ã€"æ¥ä¸‹æ¥"ã€"å€¼å¾—ä¸€æçš„æ˜¯"ï¼‰

è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼JSONï¼‰ï¼š
{{
  "opening": "å¼€åœºç™½æ–‡æœ¬ï¼ˆ10-15ç§’æœ—è¯»é‡ï¼‰",
  "detailed_hotspots": [
    {{
      "rank": 1,
      "title": "ä¼˜åŒ–åçš„å£è¯­åŒ–æ ‡é¢˜",
      "script": "è¯¦ç»†æ’­æŠ¥è„šæœ¬ï¼ˆ40-45ç§’æœ—è¯»é‡ï¼‰",
      "key_point": "æ ¸å¿ƒè§‚ç‚¹æˆ–æ•°æ®",
      "source": "æ¥æºåç§°",
      "duration": "45ç§’"
    }}
  ],
  "quick_hotspots": [
    {{
      "rank": 4,
      "title": "çƒ­ç‚¹æ ‡é¢˜",
      "script": "ä¸€å¥è¯æ‘˜è¦ï¼ˆ15-20ç§’æœ—è¯»é‡ï¼‰",
      "duration": "20ç§’"
    }}
  ],
  "closing": "ç»“å°¾æ–‡æœ¬ï¼ˆ5-10ç§’æœ—è¯»é‡ï¼‰",
  "total_duration_estimate": "3åˆ†30ç§’",
  "hotspot_count": 5
}}

è¯·åªè¾“å‡º JSONï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šè¯´æ˜ã€‚"""


class VideoScriptGenerator:
    """è§†é¢‘è„šæœ¬ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.llm_client = GeminiLLMClient()
    
    def generate(self, input_file: str, output_file: str = None) -> Dict[str, Any]:
        """
        ä»ç²¾é€‰çƒ­ç‚¹ç”Ÿæˆè§†é¢‘è„šæœ¬
        
        Args:
            input_file: ç²¾é€‰çƒ­ç‚¹æ–‡ä»¶è·¯å¾„ï¼ˆselected_YYYY-MM-DD.jsonï¼‰
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è§†é¢‘è„šæœ¬æ•°æ®
        """
        # åŠ è½½ç²¾é€‰æ•°æ®
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"ğŸ“– åŠ è½½ç²¾é€‰æ•°æ®: {data.get('selected_count', 0)} æ¡çƒ­ç‚¹")
        
        # è°ƒç”¨ LLM ç”Ÿæˆè„šæœ¬
        script = self.llm_client.generate_video_script(data)
        
        # æ„å»ºå®Œæ•´è¾“å‡º
        output = {
            'date': data.get('date'),
            'generation_time': datetime.now().isoformat(),
            'model': self.llm_client.model_name,
            'input_file': input_file,
            'video_script': script
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        if output_file:
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ è„šæœ¬å·²ä¿å­˜: {output_file}")
        
        # æ‰“å°æ‘˜è¦
        if 'opening' in script:
            print(f"\nğŸ“‹ è„šæœ¬ç»“æ„:")
            print(f"  å¼€åœº: {len(script.get('opening', ''))} å­—")
            print(f"  è¯¦ç»†æ’­æŠ¥: {len(script.get('detailed_hotspots', []))} æ¡")
            print(f"  å¿«é€Ÿæ’­æŠ¥: {len(script.get('quick_hotspots', []))} æ¡")
            print(f"  ç»“å°¾: {len(script.get('closing', ''))} å­—")
            print(f"  é¢„ä¼°æ—¶é•¿: {script.get('total_duration_estimate', 'æœªçŸ¥')}")
        
        return output


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è§†é¢‘è„šæœ¬ç”Ÿæˆå™¨')
    parser.add_argument('--input', '-i', required=True, help='ç²¾é€‰çƒ­ç‚¹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--model', '-m', help='Gemini æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰')
    
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šäº†æ¨¡å‹ï¼Œä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡
    if args.model:
        os.environ['GEMINI_MODEL'] = args.model
    
    generator = VideoScriptGenerator()
    result = generator.generate(args.input, args.output)


if __name__ == '__main__':
    main()
