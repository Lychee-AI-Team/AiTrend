#!/usr/bin/env python3
"""
AiTrend è´¨é‡æ§åˆ¶ç³»ç»Ÿ - ä¸»æµç¨‹
ç”Ÿæˆå†…å®¹ â†’ Subagentè¯„å®¡ â†’ ä¼˜åŒ–å¾ªç¯ â†’ å‘å¸ƒé«˜åˆ†å†…å®¹
"""

import json
import os
import sys
import time
from datetime import datetime
from typing import List, Dict, Any

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env')
if os.path.exists(env_path):
    with open(env_path, 'r') as f:
        for line in f:
            if '=' in line and not line.startswith('#'):
                key, value = line.strip().split('=', 1)
                os.environ[key] = value

from src.sources import create_sources
from src.sources.base import Article
from src.core.deduplicator import ArticleDeduplicator
from src.core.config_loader import load_config
from src.core.webhook_sender import DiscordWebhookSender
from src.hourly import select_best_articles, generate_unique_content, get_thread_title

REVIEW_LOG_PATH = os.path.join(os.path.dirname(__file__), '..', 'memory', 'review_log.json')
SCORE_THRESHOLD = 8.0  # é«˜åˆ†é˜ˆå€¼
MAX_ITERATIONS = 5     # æœ€å¤§ä¼˜åŒ–æ¬¡æ•°

def load_review_log() -> Dict:
    """åŠ è½½è¯„å®¡æ—¥å¿—"""
    try:
        with open(REVIEW_LOG_PATH, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        return {
            "review_sessions": [],
            "current_batch": {"batch_id": None, "articles": [], "reviews": [], "average_score": 0, "status": "pending"},
            "optimization_history": [],
            "threshold": SCORE_THRESHOLD
        }

def save_review_log(log: Dict):
    """ä¿å­˜è¯„å®¡æ—¥å¿—"""
    with open(REVIEW_LOG_PATH, 'w') as f:
        json.dump(log, f, ensure_ascii=False, indent=2)

def generate_batch(article_count: int = 5) -> List[Article]:
    """ç”Ÿæˆä¸€æ‰¹å€™é€‰å†…å®¹"""
    print(f"\n{'='*60}")
    print(f"ğŸ”„ ç”Ÿæˆæ–°æ‰¹æ¬¡å†…å®¹ (ç›®æ ‡: {article_count} æ¡)")
    print('='*60)
    
    config = load_config()
    
    # æ”¶é›†æ•°æ®
    print("\nğŸ“¡ æ”¶é›†æ•°æ®æº...")
    sources_config = config.get("sources", {})
    sources = create_sources(sources_config)
    
    all_articles = []
    for source in sources:
        if source.is_enabled():
            try:
                articles = source.fetch()
                for article in articles:
                    article.metadata['collector_source'] = source.name
                all_articles.extend(articles)
                print(f"  âœ“ {source.name}: {len(articles)} æ¡")
            except Exception as e:
                print(f"  âœ— {source.name}: {e}")
    
    print(f"\nğŸ“Š å…±æ”¶é›† {len(all_articles)} æ¡")
    
    # å»é‡
    deduplicator = ArticleDeduplicator()
    articles = deduplicator.filter_new_articles(all_articles)
    
    seen_urls = set()
    unique_articles = []
    for article in articles:
        if article.url and article.url not in seen_urls:
            seen_urls.add(article.url)
            unique_articles.append(article)
    articles = unique_articles
    
    print(f"ğŸ” å»é‡å: {len(articles)} æ¡")
    
    if len(articles) < article_count:
        print(f"âš ï¸ å¯ç”¨å†…å®¹ä¸è¶³ {article_count} æ¡ï¼Œå°†ç”Ÿæˆ {len(articles)} æ¡")
        article_count = len(articles)
    
    # é€‰æ‹©æœ€ä½³
    top_articles = select_best_articles(articles, top_n=article_count)
    
    print(f"\nâ­ é€‰ä¸­ {len(top_articles)} æ¡:")
    for i, article in enumerate(top_articles, 1):
        print(f"  {i}. [{article.source}] {article.title[:50]}...")
    
    return top_articles

def prepare_content_for_review(articles: List[Article]) -> List[Dict]:
    """å‡†å¤‡å†…å®¹ä¾›è¯„å®¡"""
    contents = []
    for article in articles:
        content = generate_unique_content(article)
        contents.append({
            "id": hash(article.url) % 10000,
            "title": get_thread_title(article),
            "original_title": article.title,
            "content": content,
            "url": article.url,
            "source": article.source,
            "metadata": article.metadata
        })
    return contents

def save_batch_for_review(contents: List[Dict]) -> str:
    """ä¿å­˜æ‰¹æ¬¡åˆ°æ—¥å¿—ï¼Œä¾›subagentè¯„å®¡"""
    log = load_review_log()
    batch_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    log["current_batch"] = {
        "batch_id": batch_id,
        "articles": contents,
        "reviews": [],
        "average_score": 0,
        "status": "pending_review",
        "created_at": datetime.now().isoformat()
    }
    
    save_review_log(log)
    
    # åŒæ—¶ä¿å­˜åˆ°å•ç‹¬æ–‡ä»¶ä¾›subagentè¯»å–
    batch_file = os.path.join(os.path.dirname(__file__), '..', 'memory', f'batch_{batch_id}.json')
    with open(batch_file, 'w') as f:
        json.dump({"batch_id": batch_id, "contents": contents}, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æ‰¹æ¬¡å·²ä¿å­˜: {batch_id}")
    print(f"ğŸ“„ è¯„å®¡æ–‡ä»¶: {batch_file}")
    
    return batch_id

def check_reviews_complete(batch_id: str) -> bool:
    """æ£€æŸ¥è¯„å®¡æ˜¯å¦å®Œæˆ"""
    log = load_review_log()
    if log["current_batch"]["batch_id"] != batch_id:
        return False
    return log["current_batch"]["status"] == "reviewed"

def get_average_score(batch_id: str) -> float:
    """è·å–å¹³å‡è¯„åˆ†"""
    log = load_review_log()
    if log["current_batch"]["batch_id"] != batch_id:
        return 0.0
    return log["current_batch"].get("average_score", 0.0)

def get_reviews(batch_id: str) -> List[Dict]:
    """è·å–è¯„å®¡è¯¦æƒ…"""
    log = load_review_log()
    if log["current_batch"]["batch_id"] != batch_id:
        return []
    return log["current_batch"].get("reviews", [])

def publish_high_score_contents(contents: List[Dict], reviews: List[Dict]):
    """å‘å¸ƒé«˜åˆ†å†…å®¹åˆ°Discord"""
    print(f"\n{'='*60}")
    print("ğŸ“¤ å‘å¸ƒé«˜åˆ†å†…å®¹åˆ°Discord")
    print('='*60)
    
    webhook_url = os.getenv('DISCORD_WEBHOOK_URL')
    if not webhook_url:
        with open('.env', 'r') as f:
            for line in f:
                if line.startswith('DISCORD_WEBHOOK_URL='):
                    webhook_url = line.strip().split('=', 1)[1]
                    break
    
    sender = DiscordWebhookSender(webhook_url)
    published = 0
    
    for content, review in zip(contents, reviews):
        score = review.get('total_score', 0)
        if score >= SCORE_THRESHOLD:
            print(f"\n  âœ… å‘å¸ƒ (è¯„åˆ†: {score}): {content['title'][:40]}...")
            result = sender.send_to_forum(content['title'], content['content'])
            if result:
                published += 1
                time.sleep(2)
        else:
            print(f"\n  âŒ è·³è¿‡ (è¯„åˆ†: {score}): {content['title'][:40]}...")
    
    print(f"\nğŸ“ˆ å‘å¸ƒå®Œæˆ: {published}/{len(contents)} æ¡")
    return published

def optimize_and_regenerate(weaknesses: List[str]) -> List[Article]:
    """æ ¹æ®å¼±ç‚¹ä¼˜åŒ–å¹¶é‡æ–°ç”Ÿæˆ"""
    print(f"\n{'='*60}")
    print("ğŸ”§ æ ¹æ®è¯„å®¡åé¦ˆä¼˜åŒ–ç­–ç•¥")
    print('='*60)
    
    print("\nğŸ“‹ è¯„å®¡å‘ç°çš„ä¸»è¦é—®é¢˜:")
    for i, weakness in enumerate(weaknesses[:5], 1):
        print(f"  {i}. {weakness}")
    
    print("\nğŸ“ åº”ç”¨ä¼˜åŒ–ç­–ç•¥...")
    # è¿™é‡Œå¯ä»¥æ ¹æ®weaknessesè°ƒæ•´ç”Ÿæˆå‚æ•°
    # ä¾‹å¦‚ï¼šå¦‚æœå¤šæ¬¡æåˆ°"ç¼ºå°‘æŠ€æœ¯ç»†èŠ‚"ï¼Œå¢åŠ æŠ€æœ¯æè¿°æƒé‡
    
    # é‡æ–°ç”Ÿæˆä¸€æ‰¹
    return generate_batch(article_count=5)

def print_review_summary(reviews: List[Dict]):
    """æ‰“å°è¯„å®¡æ±‡æ€»"""
    print(f"\n{'='*60}")
    print("ğŸ“Š è¯„å®¡ç»“æœæ±‡æ€»")
    print('='*60)
    
    total_score = 0
    for i, review in enumerate(reviews, 1):
        score = review.get('total_score', 0)
        total_score += score
        status = "âœ… é«˜åˆ†" if score >= SCORE_THRESHOLD else "âŒ ä½åˆ†"
        print(f"\n  {i}. {status} {score}/10")
        print(f"     {review.get('title', 'Unknown')[:45]}...")
        print(f"     äº®ç‚¹: {', '.join(review.get('strengths', [])[:2])}")
        print(f"     é—®é¢˜: {', '.join(review.get('weaknesses', [])[:2])}")
    
    avg = total_score / len(reviews) if reviews else 0
    print(f"\nğŸ“ˆ å¹³å‡åˆ†: {avg:.1f}/10")
    print(f"ğŸ¯ é˜ˆå€¼: {SCORE_THRESHOLD}/10")
    print(f"ğŸ“Š çŠ¶æ€: {'âœ… è¾¾æ ‡' if avg >= SCORE_THRESHOLD else 'âŒ æœªè¾¾æ ‡ï¼Œéœ€è¦ä¼˜åŒ–'}")

def main():
    """ä¸»æµç¨‹ï¼šç”Ÿæˆ â†’ è¯„å®¡ â†’ ä¼˜åŒ–å¾ªç¯ â†’ å‘å¸ƒ"""
    print("\n" + "="*60)
    print("ğŸ¯ AiTrend è´¨é‡æ§åˆ¶ç³»ç»Ÿå¯åŠ¨")
    print("="*60)
    print(f"\né…ç½®:")
    print(f"  â€¢ è¯„åˆ†é˜ˆå€¼: {SCORE_THRESHOLD}/10")
    print(f"  â€¢ æœ€å¤§ä¼˜åŒ–æ¬¡æ•°: {MAX_ITERATIONS}")
    print(f"  â€¢ æ¯æ‰¹ç”Ÿæˆ: 5æ¡å†…å®¹")
    
    iteration = 0
    current_batch = None
    
    while iteration < MAX_ITERATIONS:
        iteration += 1
        print(f"\n{'='*60}")
        print(f"ğŸ”„ ç¬¬ {iteration}/{MAX_ITERATIONS} è½®è¿­ä»£")
        print('='*60)
        
        # æ­¥éª¤1: ç”Ÿæˆå†…å®¹
        if iteration == 1 or not current_batch:
            articles = generate_batch(article_count=5)
            current_batch = prepare_content_for_review(articles)
        else:
            # ä¼˜åŒ–åé‡æ–°ç”Ÿæˆ
            articles = optimize_and_regenerate(all_weaknesses)
            current_batch = prepare_content_for_review(articles)
        
        # æ­¥éª¤2: ä¿å­˜æ‰¹æ¬¡ï¼Œç­‰å¾…è¯„å®¡
        batch_id = save_batch_for_review(current_batch)
        
        print(f"\nâ³ ç­‰å¾…Subagentå®Œæˆè¯„å®¡...")
        print(f"ğŸ’¡ Subagentåº”è¯»å–: memory/batch_{batch_id}.json")
        print(f"ğŸ’¡ è¯„å®¡åä¿å­˜åˆ°: memory/review_log.json")
        
        # åœ¨å®é™…è¿è¡Œä¸­ï¼Œè¿™é‡Œä¼šç­‰å¾…subagentå®Œæˆ
        # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å…ˆæ¨¡æ‹Ÿç­‰å¾…çŠ¶æ€
        print(f"\nâš ï¸ å½“å‰å®ç°éœ€è¦æ‰‹åŠ¨è§¦å‘Subagentè¯„å®¡")
        print(f"âš ï¸ è¯·è¿è¡Œ: python3 -m agents.reviewer {batch_id}")
        
        # å®é™…éƒ¨ç½²æ—¶ä¼šè½®è¯¢æ£€æŸ¥
        # while not check_reviews_complete(batch_id):
        #     time.sleep(10)
        
        # æ¨¡æ‹Ÿï¼šå‡è®¾è¯„å®¡å®Œæˆ
        input("\næŒ‰Enteré”®æ¨¡æ‹Ÿè¯„å®¡å®Œæˆ (å®é™…éƒ¨ç½²æ—¶ä¼šè‡ªåŠ¨æ£€æµ‹)...")
        
        # æ­¥éª¤3: æ£€æŸ¥è¯„å®¡ç»“æœ
        avg_score = get_average_score(batch_id)
        reviews = get_reviews(batch_id)
        
        print_review_summary(reviews)
        
        # æ­¥éª¤4: åˆ¤æ–­æ˜¯å¦è¾¾æ ‡
        if avg_score >= SCORE_THRESHOLD:
            print(f"\nâœ… è¯„åˆ†è¾¾æ ‡ï¼å‡†å¤‡å‘å¸ƒ...")
            publish_high_score_contents(current_batch, reviews)
            break
        else:
            print(f"\nâŒ è¯„åˆ†æœªè¾¾æ ‡ï¼Œæ”¶é›†é—®é¢˜å¹¶ä¼˜åŒ–...")
            all_weaknesses = []
            for review in reviews:
                all_weaknesses.extend(review.get('weaknesses', []))
            
            if iteration < MAX_ITERATIONS:
                print(f"\nğŸ”„ è¿›å…¥ä¸‹ä¸€è½®ä¼˜åŒ–...")
            else:
                print(f"\nâš ï¸ å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå‘å¸ƒå½“å‰æœ€é«˜åˆ†å†…å®¹...")
                publish_high_score_contents(current_batch, reviews)
    
    print(f"\n{'='*60}")
    print("âœ… è´¨é‡æ§åˆ¶ç³»ç»Ÿè¿è¡Œå®Œæˆ")
    print('='*60)

if __name__ == '__main__':
    main()
