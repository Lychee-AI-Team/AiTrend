"""
Twitter/X AI çƒ­ç‚¹ç›‘æ§ - ä½¿ç”¨ bird CLI
è·å– AI ç›¸å…³çš„ viral æ¨æ–‡å’Œæ–°äº§å“å‘å¸ƒ
"""
import subprocess
import json
import re
from typing import List, Dict, Any
from .base import DataSource, Article
import logging

logger = logging.getLogger(__name__)

class TwitterSource(DataSource):
    """Twitter AI çƒ­ç‚¹æ•°æ®æº - ä½¿ç”¨ bird CLI"""
    name = "twitter"
    
    # AI ç›¸å…³è´¦å·å’Œå…³é”®è¯
    AI_ACCOUNTS = [
        "@OpenAI", "@AnthropicAI", "@GoogleAI", "@DeepMind",
        "@xai", "@ stabilityai", "@AIatMeta",
        "@karpathy", "@ylecun", "@goodfellow_ian"
    ]
    
    # AI å…³é”®è¯ï¼ˆä¸­å›½:ç¾å›½ = 7:3ï¼‰
    # ä¸­å›½ AI å…³é”®è¯ï¼ˆ70%ï¼‰
    CN_KEYWORDS = [
        "Kimi", "é€šä¹‰åƒé—®", "æ–‡å¿ƒä¸€è¨€", "æ™ºè°±", "DeepSeek",
        "å­—èŠ‚è·³åŠ¨", "è…¾è®¯", "é˜¿é‡Œ", "ç™¾åº¦", "åä¸ºç›˜å¤",
        "ä¸­å›½AI", "å›½äº§å¤§æ¨¡å‹", "ä¸­æ–‡å¤§æ¨¡å‹", "å›½å†…é¦–å‘"
    ]
    # ç¾å›½/å›½é™… AI å…³é”®è¯ï¼ˆ30%ï¼‰
    INTL_KEYWORDS = [
        "OpenAI", "ChatGPT", "Claude", "Gemini", "Anthropic",
        "new model", "just released", "announcing"
    ]
    AI_KEYWORDS = CN_KEYWORDS + INTL_KEYWORDS
    
    def fetch(self) -> List[Article]:
        """è·å– Twitter AI ç›¸å…³å†…å®¹"""
        auth_token = self.config.get("auth_token")
        ct0 = self.config.get("ct0")
        
        if not auth_token or not ct0:
            logger.error("Twitter Cookie æœªé…ç½®")
            return []
        
        try:
            # è·å– For You æ—¶é—´çº¿
            tweets = self._fetch_timeline(auth_token, ct0)
            
            # ç­›é€‰ AI ç›¸å…³å†…å®¹
            ai_tweets = [t for t in tweets if self._is_ai_related(t)]
            
            logger.info(f"Twitter è·å– {len(ai_tweets)} æ¡ AI ç›¸å…³å†…å®¹ï¼ˆæ€»è®¡ {len(tweets)} æ¡ï¼‰")
            return ai_tweets[:10]
            
        except Exception as e:
            logger.error(f"è·å– Twitter å¤±è´¥: {e}")
            return []
    
    def _fetch_timeline(self, auth_token: str, ct0: str) -> List[Article]:
        """è·å– Twitter æ—¶é—´çº¿"""
        # ä½¿ç”¨ bird CLI è·å–æ—¶é—´çº¿
        cmd = f"""export NVM_DIR="$HOME/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \\. "$NVM_DIR/nvm.sh" && nvm use --lts 2>/dev/null && \
bird home -n 100 --auth-token "{auth_token}" --ct0 "{ct0}" --json 2>/dev/null"""
        
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=60)
        
        if result.returncode != 0:
            logger.warning(f"bird CLI æ‰§è¡Œå¤±è´¥: {result.stderr}")
            return []
        
        # è§£æ JSON è¾“å‡º
        lines = [l for l in result.stdout.split('\n') if l.strip() and not l.startswith('Now using node')]
        
        try:
            tweets_data = json.loads('\n'.join(lines))
            if isinstance(tweets_data, list):
                return self._parse_tweets(tweets_data)
            return []
        except json.JSONDecodeError:
            logger.warning("Twitter æ•°æ®è§£æå¤±è´¥")
            return []
    
    def _parse_tweets(self, tweets_data: List[Dict]) -> List[Article]:
        """è§£ææ¨æ–‡æ•°æ®"""
        tweets = []
        
        for tweet in tweets_data:
            try:
                text = tweet.get('text', '').strip()
                author = tweet.get('author', {}).get('username', '')
                tweet_id = tweet.get('id', '')
                likes = tweet.get('likeCount', 0)
                retweets = tweet.get('retweetCount', 0)
                
                # è¿‡æ»¤ä½è´¨é‡æ¨æ–‡
                if not text or len(text) < 30:
                    continue
                
                # æ¸…ç†æ–‡æœ¬
                text = self._clean_text(text)
                
                url = f"https://x.com/{author}/status/{tweet_id}"
                
                tweets.append(Article(
                    title=f"[Twitter] @{author}",
                    url=url,
                    summary=text[:200],
                    source="twitter",
                    metadata={
                        "author": author,
                        "likes": likes,
                        "retweets": retweets
                    }
                ))
                
            except Exception as e:
                logger.debug(f"è§£ææ¨æ–‡å¤±è´¥: {e}")
                continue
        
        return tweets
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ¨æ–‡æ–‡æœ¬"""
        # ç§»é™¤ t.co é“¾æ¥
        text = re.sub(r'https://t\.co/\S+', '', text)
        # ç§»é™¤å›¾ç‰‡/è§†é¢‘æ ‡è®°
        text = re.sub(r'ğŸ–¼ï¸\s*', '', text)
        text = re.sub(r'ğŸ¬\s*', '', text)
        # æ¸…ç†å¤šä½™ç©ºæ ¼
        text = ' '.join(text.split())
        return text.strip()
    
    def _is_ai_related(self, tweet: Article) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯ AI ç›¸å…³æ¨æ–‡"""
        text = (tweet.title + " " + tweet.summary).lower()
        author = tweet.metadata.get('author', '').lower()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ AI ç›¸å…³è´¦å·
        ai_authors = [
            'openai', 'anthropicai', 'googleai', 'deepmind', 'xai',
            'karpathy', 'ylecun', 'goodfellow', 'jackclark',
            'moltbook', 'openclaw'
        ]
        if any(ai in author for ai in ai_authors):
            return True
        
        # æ£€æŸ¥å…³é”®è¯
        if any(keyword in text for keyword in self.AI_KEYWORDS):
            return True
        
        # æ£€æŸ¥ AI å…³é”®è¯
        ai_terms = ['ai', 'llm', 'gpt', 'claude', 'model', 'tool', 'app', 'launch']
        if any(term in text for term in ai_terms):
            # é¢å¤–æ£€æŸ¥çƒ­åº¦
            if tweet.metadata.get('likes', 0) > 50:
                return True
        
        return False
