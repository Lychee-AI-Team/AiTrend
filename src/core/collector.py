"""
æ ¸å¿ƒæ”¶é›†å™¨ - çº¯æ ‡å‡†åº“ç‰ˆæœ¬ï¼ˆåŒæ­¥ï¼‰
æ•´åˆæ•°æ®æºã€AIæ€»ç»“ã€è‡ªéªŒè¯ã€å¤šæ¸ é“å‘é€
"""
import json
import http.client
from typing import List, Dict, Any, Tuple
from datetime import datetime

from src.sources import create_sources
from src.core.validator import SelfValidator
from src.sources.base import Article

import logging

logger = logging.getLogger(__name__)

class TrendCollector:
    """è¶‹åŠ¿æ”¶é›†å™¨ - çº¯æ ‡å‡†åº“ç‰ˆæœ¬"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.validator = SelfValidator(
            auto_fix=config.get("advanced", {}).get("validation", {}).get("auto_fix", True)
        )
        self.max_retries = config.get("advanced", {}).get("max_retries", 3)
    
    def run(self) -> Tuple[bool, str]:
        """æ‰§è¡Œå®Œæ•´æ”¶é›†æµç¨‹ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        logger.info("ğŸš€ å¼€å§‹ AiTrend æ”¶é›†ä»»åŠ¡")
        
        for attempt in range(self.max_retries):
            try:
                # 1. æ”¶é›†æ•°æ®
                articles = self._collect_data()
                if not articles:
                    logger.warning("âš ï¸ æœªæ”¶é›†åˆ°ä»»ä½•æ•°æ®")
                    if attempt < self.max_retries - 1:
                        continue
                    return False, "æœªæ”¶é›†åˆ°æ•°æ®"
                
                # 2. AI æ€»ç»“
                summary = self._summarize(articles)
                
                # 3. è‡ªéªŒè¯
                is_valid, validation_result = self.validator.full_validate(
                    [self._article_to_dict(a) for a in articles],
                    summary,
                    "feishu"
                )
                
                final_content = validation_result.get("fixed_content", summary)
                
                # 4. å‘é€
                send_results = self._send_to_all_channels(final_content)
                
                # 5. è¿”å›ç»“æœ
                success_count = sum(1 for r in send_results if r[1])
                total_count = len(send_results)
                
                if success_count > 0:
                    msg = f"âœ… ä»»åŠ¡å®Œæˆ: æ”¶é›† {len(articles)} æ¡ï¼ŒæˆåŠŸå‘é€ {success_count}/{total_count} æ¸ é“"
                    logger.info(msg)
                    return True, final_content
                else:
                    raise RuntimeError("æ‰€æœ‰æ¸ é“å‘é€å¤±è´¥")
                    
            except Exception as e:
                logger.error(f"âŒ ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
                if attempt == self.max_retries - 1:
                    return False, f"ä»»åŠ¡å¤±è´¥: {e}"
                import time
                time.sleep(2 ** attempt)
        
        return False, "æœªçŸ¥é”™è¯¯"
    
    def _article_to_dict(self, article: Article) -> Dict:
        """Article è½¬ dict"""
        return {
            "title": article.title,
            "url": article.url,
            "summary": article.summary,
            "source": article.source
        }
    
    def _collect_data(self) -> List[Article]:
        """ä»æ‰€æœ‰æ•°æ®æºæ”¶é›†æ•°æ®ï¼ˆåŒæ­¥ï¼‰"""
        sources_config = self.config.get("sources", {})
        sources = create_sources(sources_config)
        
        if not sources:
            logger.error("æ²¡æœ‰å¯ç”¨çš„æ•°æ®æº")
            return []
        
        logger.info(f"ğŸ“Š å¼€å§‹ä» {len(sources)} ä¸ªæ•°æ®æºæ”¶é›†")
        
        all_articles = []
        for source in sources:
            if source.is_enabled():
                try:
                    articles = source.fetch()
                    all_articles.extend(articles)
                except Exception as e:
                    logger.error(f"æ•°æ®æº {source.name} é”™è¯¯: {e}")
        
        logger.info(f"ğŸ“Š å…±æ”¶é›† {len(all_articles)} æ¡åŸå§‹æ•°æ®")
        return all_articles
    
    def _summarize(self, articles: List[Article]) -> str:
        """AI æ€»ç»“ï¼ˆä½¿ç”¨ http.clientï¼‰"""
        summarizer_config = self.config.get("summarizer", {})
        
        if not summarizer_config.get("enabled", True):
            logger.info("âš ï¸ AI æ€»ç»“å·²ç¦ç”¨ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
            return self._format_raw(articles)
        
        try:
            provider = summarizer_config.get("provider", "gemini")
            if provider == "gemini":
                return self._summarize_with_gemini(articles, summarizer_config)
            else:
                logger.warning(f"æš‚ä¸æ”¯æŒçš„æä¾›å•†: {provider}")
                return self._format_raw(articles)
        except Exception as e:
            logger.error(f"âŒ AI æ€»ç»“å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
            return self._format_raw(articles)
    
    def _summarize_with_gemini(self, articles: List[Article], config: Dict) -> str:
        """ä½¿ç”¨ Gemini API æ€»ç»“"""
        api_key = config.get("api_key")
        logger.info(f"DEBUG: Gemini API Key = {api_key[:10]}..." if api_key else "None")
        if not api_key:
            raise ValueError("Gemini API Key æœªé…ç½®")
        
        # è·å–è¯­è¨€è®¾ç½®
        language = self.config.get("language", "zh")
        lang_names = {
            "zh": "ç®€ä½“ä¸­æ–‡",
            "en": "English",
            "ja": "æ—¥æœ¬èª",
            "ko": "í•œêµ­ì–´",
            "es": "EspaÃ±ol"
        }
        output_lang = lang_names.get(language, "ç®€ä½“ä¸­æ–‡")
        
        content = self._format_for_summary(articles)
        prompt = f"""ä½ æ˜¯ AI åœˆ KOLã€‚åŸºäºä»¥ä¸‹æ•°æ®è¾“å‡ºæœ¬å‘¨æœ€å€¼å¾—æ¨èçš„ AI äº§å“ã€‚

ã€è¾“å‡ºè¯­è¨€è¦æ±‚ã€‘
å¿…é¡»ä½¿ç”¨ {output_lang} è¾“å‡ºæ‰€æœ‰å†…å®¹ã€‚

ã€æ•°æ®ã€‘
{content}

ã€ç­›é€‰è¦æ±‚ã€‘
1. åˆ é™¤å®˜æ–¹æ–°é—»ï¼ˆå…¬å¸å‘å¸ƒã€è¡Œä¸šæŠ¥é“ã€èèµ„æ–°é—»ï¼‰
2. åˆ é™¤çº¯æ¨¡å‹å‚æ•°å¯¹æ¯”ï¼ˆè¶…è¶ŠGPTç­‰æ–°é—»ï¼‰
3. ä¼˜å…ˆä¿ç•™ï¼šç”¨æˆ·çœŸå®ä½“éªŒã€ç‹¬ç«‹å¼€å‘è€…é¡¹ç›®ã€å¯ç«‹å³ä½¿ç”¨çš„å·¥å…·
4. åªè¾“å‡ºç”¨æˆ·ä»Šå¤©èƒ½å¼€å§‹ç”¨çš„äº§å“

ã€è¾“å‡ºæ ¼å¼ã€‘
1. **äº§å“å**
@ç”¨æˆ·å å‘ç°äº†è¿™ä¸ªå·¥å…·...
[2-3æ®µå£è¯­åŒ–æè¿°ï¼Œä½¿ç”¨{output_lang}]
ğŸ‘‰ é“¾æ¥

è¶‹åŠ¿æ´å¯Ÿ
[1-2æ®µè¿è´¯å£è¯­ï¼Œä½¿ç”¨{output_lang}]

---
æ•°æ®æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d')}"""
        
        conn = http.client.HTTPSConnection("generativelanguage.googleapis.com", timeout=60)
        try:
            model = config.get("model", "gemini-2.5-flash")
            path = f"/v1beta/models/{model}:generateContent"
            
            data = json.dumps({
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {
                    "temperature": config.get("temperature", 0.7),
                    "maxOutputTokens": config.get("max_tokens", 2000)
                }
            }, ensure_ascii=False)
            
            headers = {
                "Content-Type": "application/json"
            }
            
            conn.request("POST", f"{path}?key={api_key}", body=data.encode('utf-8'), headers=headers)
            response = conn.getresponse()
            
            if response.status != 200:
                error_body = response.read().decode()
                raise RuntimeError(f"Gemini API é”™è¯¯: {response.status} - {error_body}")
            
            result = json.loads(response.read().decode())
            text = result["candidates"][0]["content"]["parts"][0]["text"]
            
            # æ¸…ç†æ ¼å¼
            text = text.replace('**', '').replace('*', '').replace('__', '')
            text = text.replace('<', '').replace('>', '')
            
            # åˆ é™¤æ ‡é¢˜è¡Œ
            import re
            text = re.sub(r'^[ğŸ”¥\s]*AI[\s]*åœˆ[\s]*æœ¬å‘¨[\s]*çƒ­ç‚¹[\sï¼Œ,ã€]*\n?', '', text, flags=re.MULTILINE)
            text = re.sub(r'^[\s]*ç›´æ¥[\s]*ä¸Š[\s]*å¹²è´§[\sï¼!]*\n?', '', text, flags=re.MULTILINE)
            text = text.strip()
            
            logger.info("âœ… AI æ€»ç»“å®Œæˆ")
            return text
            
        finally:
            conn.close()
    
    def _format_for_summary(self, articles: List[Article]) -> str:
        """æ ¼å¼åŒ–ä¸ºæ€»ç»“è¾“å…¥ - ç²¾é€‰å¤šæºçƒ­ç‚¹"""
        # æŒ‰æ¥æºåˆ†ç±»
        by_source = {}
        for a in articles:
            source = a.source
            if source not in by_source:
                by_source[source] = []
            by_source[source].append(a)
        
        # æ¯ä¸ªæ¥æºå–å‰å‡ æ¡
        selected = []
        
        # ä¼˜å…ˆå–ç”¨æˆ·ç”Ÿæˆå†…å®¹å¹³å°ï¼ˆè¿‡æ»¤å®˜æ–¹æ–°é—»ï¼‰
        priority_order = ['twitter', 'reddit', 'producthunt', 'hackernews', 'github_trending', 'brave_search']
        for source in priority_order:
            if source in by_source:
                # è¿‡æ»¤æ‰å®˜æ–¹æ–°é—»
                if source == 'brave_search':
                    posts = [p for p in by_source[source] if not p.metadata.get("is_official_news", False)][:5]
                else:
                    posts = by_source[source][:5]
                selected.extend(posts)
        
        lines = []
        for i, article in enumerate(selected[:20], 1):  # æ€»å…±æœ€å¤š20æ¡
            source_tag = f"[{article.source.upper()}]"
            
            # æ£€æµ‹å†…å®¹ç±»å‹æ ‡è®°
            content_type = ""
            if article.source == "brave_search" and article.metadata.get("is_official_news"):
                content_type = "[å®˜æ–¹æ–°é—»-ä½æƒé‡]"
            elif article.source in ["twitter", "reddit"]:
                content_type = "[ç”¨æˆ·åˆ†äº«]"
            elif article.source == "producthunt":
                content_type = "[äº§å“å‘å¸ƒ]"
            elif article.source == "hackernews":
                content_type = "[å¼€å‘è€…åˆ†äº«]"
            
            lines.append(f"{i}. {source_tag} {content_type} {article.title}")
            lines.append(f"   æè¿°: {article.summary[:150]}")
            lines.append(f"   é“¾æ¥: {article.url}")
            lines.append("")
        return "\n".join(lines)
    
    def _format_raw(self, articles: List[Article]) -> str:
        """æ ¼å¼åŒ–åŸå§‹æ•°æ®ï¼ˆå¤‡ç”¨ï¼‰"""
        lines = ["ğŸ”¥ AI çƒ­ç‚¹èµ„è®¯", ""]
        
        for i, article in enumerate(articles[:10], 1):
            lines.append(f"{i}. {article.title}")
            lines.append(f"   æ¥æº: {article.source}")
            lines.append(f"   é“¾æ¥: {article.url}")
            lines.append("")
        
        return "\n".join(lines)
    
    def _send_to_all_channels(self, content: str) -> List[Tuple[str, bool]]:
        """å‘é€åˆ°æ‰€æœ‰å¯ç”¨çš„æ¸ é“"""
        channels_config = self.config.get("channels", {})
        results = []
        
        for name, channel_config in channels_config.items():
            if not isinstance(channel_config, dict):
                continue
            if not channel_config.get("enabled", False):
                continue
            
            try:
                if name == "console":
                    success = self._send_console(content)
                elif name == "feishu":
                    success = self._send_feishu(content, channel_config)
                else:
                    success = False
                
                results.append((name, success))
            except Exception as e:
                logger.error(f"æ¸ é“ {name} å‘é€å¤±è´¥: {e}")
                results.append((name, False))
        
        return results
    
    def _send_console(self, content: str) -> bool:
        """å‘é€åˆ°æ§åˆ¶å°"""
        print("\n" + "="*50)
        print("ğŸ“¤ æ¶ˆæ¯å†…å®¹:")
        print("="*50)
        print(content[:1000] + "..." if len(content) > 1000 else content)
        print("="*50 + "\n")
        
        # ä¿å­˜å®Œæ•´å†…å®¹åˆ°æ–‡ä»¶
        import os
        output_file = "/tmp/aitrend_full_content.txt"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ’¾ å®Œæ•´å†…å®¹å·²ä¿å­˜åˆ°: {output_file}")
        
        return True
    
    def _send_feishu(self, content: str, config: Dict) -> bool:
        """å‘é€åˆ°é£ä¹¦"""
        app_id = config.get("app_id")
        app_secret = config.get("app_secret")
        target = config.get("target")
        
        if not all([app_id, app_secret, target]):
            logger.error("é£ä¹¦é…ç½®ä¸å®Œæ•´")
            return False
        
        try:
            # è·å– token
            token = self._get_feishu_token(app_id, app_secret)
            if not token:
                return False
            
            # å‘é€æ¶ˆæ¯
            conn = http.client.HTTPSConnection("open.feishu.cn", timeout=30)
            try:
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json"
                }
                
                data = json.dumps({
                    "receive_id": target,
                    "msg_type": "text",
                    "content": json.dumps({"text": content}, ensure_ascii=False)
                })
                
                conn.request("POST", "/open-apis/im/v1/messages?receive_id_type=chat_id", 
                           body=data, headers=headers)
                response = conn.getresponse()
                result = json.loads(response.read().decode())
                
                if result.get("code") == 0:
                    logger.info("âœ… Feishu å‘é€æˆåŠŸ")
                    return True
                else:
                    logger.error(f"âŒ Feishu å‘é€å¤±è´¥: {result.get('msg')}")
                    return False
            finally:
                conn.close()
                
        except Exception as e:
            logger.error(f"âŒ Feishu å‘é€å¼‚å¸¸: {e}")
            return False
    
    def _get_feishu_token(self, app_id: str, app_secret: str) -> str:
        """è·å–é£ä¹¦ token"""
        conn = http.client.HTTPSConnection("open.feishu.cn", timeout=10)
        try:
            data = json.dumps({
                "app_id": app_id,
                "app_secret": app_secret
            })
            
            headers = {"Content-Type": "application/json"}
            conn.request("POST", "/open-apis/auth/v3/tenant_access_token/internal",
                       body=data, headers=headers)
            
            response = conn.getresponse()
            result = json.loads(response.read().decode())
            
            if result.get("code") == 0:
                return result["tenant_access_token"]
            else:
                logger.error(f"è·å– Feishu token å¤±è´¥: {result.get('msg')}")
                return ""
        finally:
            conn.close()
