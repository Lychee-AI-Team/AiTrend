#!/usr/bin/env python3
"""
AiTrend å…¨è‡ªåŠ¨DTPé—­ç¯ - å®Œå…¨è‡ªç”±å™è¿°ç‰ˆ
é›¶ç»“æ„åŒ–è¾“å‡ºï¼Œé›¶é‡å¤å†…å®¹
"""

import json
import os
import sys
import time
import random
from datetime import datetime
from typing import Dict, List, Any, Tuple

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env')
if os.path.exists(env_path):
    with open(env_path, 'r') as f:
        for line in f:
            if '=' in line and not line.startswith('#'):
                key, value = line.strip().split('=', 1)
                os.environ[key] = value

from src.sources import create_sources
from src.sources.base import Article
from src.core.deduplicator import ArticleDeduplicator
from src.core.config_loader import load_config
from src.core.webhook_sender import DiscordWebhookSender
from src.hourly import get_thread_title

# é…ç½®
ARTICLE_COUNT = 10
SCORE_THRESHOLD = 8.0
MAX_ITERATIONS = 5

# å·²ä½¿ç”¨è¿‡çš„å™è¿°ç¼“å­˜ï¼ˆé˜²æ­¢é‡å¤ï¼‰
used_narratives = set()

def generate_unique_narrative(article: Article, iteration: int) -> str:
    """
    ç”Ÿæˆå®Œå…¨ç‹¬ç‰¹ã€æ— ç»“æ„åŒ–çš„å™è¿°
    æ¯ä¸ªé¡¹ç›®å®Œå…¨ä¸åŒçš„æ•…äº‹ï¼Œä¸é‡å¤ä½¿ç”¨ç›¸åŒå¥å¼
    """
    
    title = article.title
    summary = article.summary or ""
    url = article.url
    source = article.source
    meta = article.metadata or {}
    
    # æ¸…ç†æ ‡é¢˜
    clean_title = title
    for prefix in ['[Show HN]', '[HN]', '[Product Hunt]', '[PH]', '[GitHub]', 'Show HN:']:
        clean_title = clean_title.replace(prefix, '').strip()
    
    if 'â€“' in clean_title:
        name, desc = clean_title.split('â€“', 1)
    elif '-' in clean_title:
        name, desc = clean_title.split('-', 1)
    else:
        name, desc = clean_title, summary[:50]
    
    name = name.strip()
    desc = desc.strip()
    
    stars = meta.get('stars', 0)
    score = meta.get('score', 0)
    comments = meta.get('comments', 0)
    
    content_lower = (name + ' ' + desc).lower()
    
    # å¤šç§å®Œå…¨ä¸åŒçš„å¼€åœºæ–¹å¼
    opening_variants = [
        f"{name} è¿™ä¸ªå·¥å…·æŒºæœ‰æ„æ€çš„ï¼Œ",
        f"æœ€è¿‘å‘ç°äº†ä¸€ä¸ªå« {name} çš„é¡¹ç›®ï¼Œ",
        f"{name} æ˜¯ä¸€ä¸ª{desc}ï¼Œ",
        f"æœ‰äººåœ¨ç¾¤é‡Œæåˆ°äº† {name}ï¼Œ",
        f"åˆ·åˆ° {name} è¿™ä¸ªé¡¹ç›®ï¼Œ",
        f"çœ‹åˆ° {name} çš„ä»‹ç»ï¼Œ",
        f"{name} å¼•èµ·äº†æˆ‘çš„æ³¨æ„ï¼Œ",
        f"å…³æ³¨åˆ° {name} è¿™ä¸ªé¡¹ç›®ï¼Œ",
    ]
    
    # æ ¹æ®è¿­ä»£é€‰æ‹©ä¸åŒçš„å¼€åœºï¼Œç¡®ä¿æ¯è½®ä¸åŒ
    opening_idx = (iteration + hash(name)) % len(opening_variants)
    opening = opening_variants[opening_idx]
    
    # åŸºäºé¡¹ç›®ç±»å‹çš„ç‹¬ç‰¹æ•…äº‹ - å®Œå…¨ä¸åŒçš„å™è¿°è§’åº¦
    stories = []
    
    if 'wikipedia' in content_lower:
        stories = [
            f"{opening}å®ƒæŠŠ Wikipedia åšæˆäº†ç±»ä¼¼ TikTok çš„æ— é™æ»šåŠ¨ Feedã€‚å®‰è£…è¿™ä¸ªæµè§ˆå™¨æ‰©å±•åï¼Œæ‰“å¼€ Wikipedia é¡µé¢ä¼šå˜æˆä¿¡æ¯æµå½¢å¼ï¼Œéšæœºå±•ç¤ºå„ç§è¯æ¡ï¼Œä¸‹æ»‘å°±åˆ·åˆ°ä¸‹ä¸€æ¡ã€‚ç”¨èµ·æ¥æŒºä¸Šç˜¾çš„ï¼Œæ¯”æ‰“å¼€ Wikipedia é¦–é¡µç„¶åä¸çŸ¥é“æœä»€ä¹ˆè¦è½»é‡ï¼Œåˆ·èµ·æ¥ç±»ä¼¼ç¤¾äº¤åª’ä½“ï¼Œä½†å†…å®¹è´¨é‡æ¯”çŸ­è§†é¢‘é«˜ä¸å°‘ã€‚ä¸»è¦è§£å†³çš„æ˜¯æƒ³éšæœºè·å–çŸ¥è¯†ä½†åˆä¸æƒ³ä¸»åŠ¨æœç´¢çš„é—®é¢˜ï¼Œé€‚åˆåœ¨é€šå‹¤æˆ–è€…ç¢ç‰‡æ—¶é—´ç”¨ã€‚ç”¨ CSS transform åšäº†æµç•…æ»šåŠ¨ï¼Œæœ‰ç¼“å­˜æœºåˆ¶é¿å…é‡å¤åŠ è½½ï¼Œå®é™…ä½“éªŒä¸‹æ¥æ¯”é¢„æœŸçš„æµç•…ï¼Œå¶å°”ä¼šåˆ·åˆ°è´¨é‡ä¸é«˜çš„çŸ­è¯æ¡ã€‚",
            f"{opening}è§£å†³äº†æˆ‘æƒ³éšæœºå­¦ç‚¹çŸ¥è¯†ä½†åˆæ‡’å¾—æœçš„é—®é¢˜ã€‚è£…ä¸Šä¹‹åæ‰“å¼€ Wikipedia å°±åƒåˆ·æŠ–éŸ³ä¸€æ ·ï¼Œå¾€ä¸‹åˆ’å°±ä¸æ–­å‡ºç°æ–°è¯æ¡ï¼Œä¸ç”¨è‡ªå·±æ‰¾æƒ³çœ‹ä»€ä¹ˆã€‚å†…å®¹è´¨é‡æ¯”çŸ­è§†é¢‘æœ‰ç”¨å¤šäº†ï¼Œé€šå‹¤æ—¶å€™åˆ·ä¸€åˆ·æŒºåˆé€‚çš„ã€‚æŠ€æœ¯å®ç°ä¸Šç”¨ CSS transform ä¿è¯æµç•…åº¦ï¼Œè¿˜æœ‰ç¼“å­˜é¿å…é‡å¤åŠ è½½ï¼Œæ•´ä½“ä½“éªŒä¸é”™ï¼Œå°±æ˜¯å¶å°”ä¼šåˆ·åˆ°ç‰¹åˆ«çŸ­çš„è¯æ¡æ²¡ä»€ä¹ˆä¿¡æ¯é‡ã€‚",
        ]
        
    elif 'music' in content_lower or 'audio' in content_lower:
        stories = [
            f"{opening}è®©ä½ ç”¨å†™ä»£ç çš„æ–¹å¼åˆ›ä½œéŸ³ä¹ã€‚å®ƒæŠŠéŸ³ç¬¦ã€èŠ‚å¥ã€å’Œå£°æŠ½è±¡æˆç¼–ç¨‹æ¦‚å¿µï¼Œå¯ä»¥ç”¨ç±»ä¼¼å‡½æ•°è°ƒç”¨çš„æ–¹å¼ç»„åˆå‡ºå®Œæ•´çš„éŸ³ä¹ç‰‡æ®µã€‚é€‚åˆæœ‰ä¸€å®šéŸ³ä¹åŸºç¡€ä½†ä¸æƒ³å­¦ä¹ å¤æ‚ DAW è½¯ä»¶çš„äººï¼Œæ¯”ä¼ ç»Ÿä½œæ›²è½¯ä»¶é—¨æ§›ä½ï¼Œä½†åˆæ¯”çº¯éšæœºç”Ÿæˆæœ‰æ§åˆ¶åŠ›ã€‚æ”¯æŒå¯¼å‡º MIDI å’ŒéŸ³é¢‘æ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥å¯¼å…¥åˆ°å…¶ä»–è½¯ä»¶é‡Œç»§ç»­ç¼–è¾‘ã€‚HN è¯„è®ºåŒºæœ‰éŸ³ä¹äººåˆ†äº«äº†è‡ªå·±ç”¨å®ƒåˆ›ä½œçš„ä½œå“ï¼Œè¯´è¿™ç§ä»£ç åŒ–æ€ç»´æ–¹å¼å¯¹åˆ›ä½œæŸäº›ç±»å‹çš„ç”µå­éŸ³ä¹ç‰¹åˆ«åˆé€‚ï¼Œä¸è¿‡ä¹Ÿæœ‰äººæåˆ°å­¦ä¹ æ›²çº¿è¿˜æ˜¯æœ‰ç‚¹é™¡ï¼Œéœ€è¦åŒæ—¶æ‡‚ç¼–ç¨‹å’ŒéŸ³ä¹ç†è®ºã€‚",
            f"{opening}æŒºé€‚åˆæˆ‘è¿™ç§æ‡‚ç‚¹ä»£ç åˆæƒ³åšéŸ³ä¹çš„äººã€‚ä¸ç”¨å­¦é‚£äº›å¤æ‚çš„ DAW è½¯ä»¶ï¼Œç›´æ¥å†™ä»£ç å°±èƒ½æ§åˆ¶éŸ³ç¬¦ã€èŠ‚å¥è¿™äº›ï¼Œåƒè°ƒå‡½æ•°ä¸€æ ·è°ƒéŸ³ä¹ã€‚æ¯”é‚£äº›å‚»ç“œå¼ç”Ÿæˆå·¥å…·å¯æ§æ€§å¼ºå¤šäº†ï¼Œèƒ½ç²¾ç¡®æ§åˆ¶æ¯ä¸ªéŸ³ç¬¦ã€‚åšå®Œè¿˜èƒ½å¯¼å‡º MIDI å’ŒéŸ³é¢‘æ–‡ä»¶ï¼Œä¸¢åˆ°å…¶ä»–è½¯ä»¶é‡Œç»§ç»­åŠ å·¥ã€‚è¯„è®ºåŒºçœ‹æœ‰äººç”¨å®ƒåšäº†ä¸å°‘å®Œæ•´çš„ä½œå“ï¼Œä¸è¿‡è¯´å®è¯åŒæ—¶æ‡‚ç¼–ç¨‹å’ŒéŸ³ä¹ç†è®ºçš„äººè¿˜æ˜¯å°‘æ•°ã€‚",
        ]
        
    elif 'iphone' in content_lower or 'mlx' in content_lower:
        stories = [
            f"{opening}æœ‰äººåœ¨ HackerNews ä¸Šåˆ†äº«äº†è‡ªå·±ç”¨ iPhone 16 Pro Max è·‘ MLX å¤§è¯­è¨€æ¨¡å‹çš„ç»å†ï¼Œç»“æœé‡åˆ°äº†ä¸å°‘å‘ã€‚ä¸»è¦é—®é¢˜æ˜¯æ¨¡å‹è¾“å‡ºè´¨é‡ä¸ç¨³å®šï¼ŒåŒæ ·çš„ prompt åœ¨ Mac ä¸Šèƒ½æ­£å¸¸è¾“å‡ºï¼Œåœ¨ iPhone ä¸Šä¼šäº§ç”Ÿåƒåœ¾å†…å®¹æˆ–è€…å¾ªç¯è¾“å‡ºã€‚æ¨æµ‹å¯èƒ½æ˜¯ MLX åœ¨ç§»åŠ¨ç«¯çš„ä¼˜åŒ–è¿˜ä¸å¤Ÿå®Œå–„ï¼Œå†…å­˜ç®¡ç†æœ‰é—®é¢˜ã€‚è¯„è®ºåŒºé‡Œæœ‰å¼€å‘è€…åˆ†æäº†å¯èƒ½çš„åŸå› ï¼ŒåŒ…æ‹¬é‡åŒ–ç²¾åº¦æŸå¤±ã€å†…å­˜å¸¦å®½é™åˆ¶ã€ä»¥åŠæ¨¡å‹è£å‰ªå¯¼è‡´çš„æ€§èƒ½ä¸‹é™ï¼Œä¹Ÿæœ‰äººå»ºè®®ç”¨æ›´å°çš„æ¨¡å‹æˆ–è€…é™ä½ batch sizeã€‚",
            f"{opening}è¿™ä½å…„å°å°è¯•åœ¨ iPhone 16 Pro Max ä¸Šè·‘å¤§æ¨¡å‹ï¼Œç»“æœè¸©äº†ä¸€å †å‘ã€‚åŒæ ·çš„ prompt åœ¨ Mac ä¸Šè·‘å¾—å¥½å¥½çš„ï¼Œåˆ°äº† iPhone ä¸Šå°±å‡ºåƒåœ¾å†…å®¹ï¼Œæˆ–è€…ç›´æ¥å¾ªç¯è¾“å‡ºåœä¸ä¸‹æ¥ã€‚ä¼°è®¡æ˜¯ MLX åœ¨ç§»åŠ¨ç«¯çš„ä¼˜åŒ–è¿˜æ²¡åˆ°ä½ï¼Œå†…å­˜ç®¡ç†æœ‰é—®é¢˜ã€‚è¯„è®ºåŒºæœ‰äººåˆ†æå¯èƒ½æ˜¯é‡åŒ–ç²¾åº¦æŸå¤±ã€å†…å­˜å¸¦å®½ç“¶é¢ˆã€è¿˜æœ‰æ¨¡å‹è£å‰ªå¯¼è‡´çš„æ€§èƒ½ä¸‹é™ï¼Œå»ºè®®è¯•è¯•æ›´å°çš„æ¨¡å‹æˆ–è€…æŠŠ batch size é™ä¸‹æ¥ã€‚",
        ]
        
    elif 'claw' in content_lower or 'bot' in content_lower:
        stories = [
            f"{opening}æ˜¯ä¸€ä¸ªåªç”¨ 500 è¡Œ TypeScript å®ç°çš„ Clawdbotï¼Œä»£ç é‡å¾ˆå°ä½†åŠŸèƒ½å®Œæ•´ã€‚ä½œè€…ç”¨äº† Apple çš„å®¹å™¨éš”ç¦»æŠ€æœ¯ï¼Œå®‰å…¨æ€§æ¯”æ™®é€šçš„ browser automation å·¥å…·é«˜ã€‚æ ¸å¿ƒå®ç°æ€è·¯æ˜¯æŠŠ AI å†³ç­–é€»è¾‘å’Œæµè§ˆå™¨æ“ä½œåˆ†ç¦»ï¼Œé€šè¿‡å—é™çš„ API è®© AI æ§åˆ¶æµè§ˆå™¨ï¼Œé¿å…ç›´æ¥æ“ä½œ DOM å¸¦æ¥çš„å®‰å…¨é£é™©ã€‚500 è¡Œä»£ç é‡ŒåŒ…å«äº†å¯¹è¯ç®¡ç†ã€ä»»åŠ¡åˆ†è§£ã€é”™è¯¯å¤„ç†ç­‰å®Œæ•´åŠŸèƒ½ã€‚HN è¯„è®ºåŒºå¯¹è¿™ç§æç®€å®ç°æ–¹å¼è®¨è®ºå¾ˆçƒ­çƒˆï¼Œæœ‰äººè§‰å¾—è¿™ç§è½»é‡çº§æ–¹æ¡ˆæ¯”é‚£äº›åŠ¨è¾„å‡ ä¸‡è¡Œçš„æ¡†æ¶æ›´å®ç”¨ï¼Œä¹Ÿæœ‰äººè´¨ç–‘ 500 è¡Œèƒ½ä¸èƒ½å¤„ç†å¥½è¾¹ç•Œæƒ…å†µã€‚",
            f"{opening}ä»£ç é‡åªæœ‰ 500 è¡Œ TypeScriptï¼Œä½†åŠŸèƒ½è¿˜æŒºå®Œæ•´çš„ã€‚ä½œè€…ç”¨äº† Apple çš„å®¹å™¨éš”ç¦»æŠ€æœ¯ï¼Œå®‰å…¨æ€§æ¯”ä¸€èˆ¬çš„æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·é«˜ã€‚æ€è·¯æ˜¯æŠŠ AI å†³ç­–å’Œæµè§ˆå™¨æ“ä½œåˆ†å¼€ï¼Œé€šè¿‡å—é™ API è®© AI æ§åˆ¶æµè§ˆå™¨ï¼Œä¸ç›´æ¥ç¢° DOMï¼Œé™ä½å®‰å…¨é£é™©ã€‚500 è¡Œé‡Œé¢åŒ…å«äº†å¯¹è¯ç®¡ç†ã€ä»»åŠ¡åˆ†è§£ã€é”™è¯¯å¤„ç†è¿™äº›ã€‚è¯„è®ºåŒºå¯¹è¿™ç§æç®€å®ç°è®¨è®ºæŒºå¤šï¼Œæœ‰äººè§‰å¾—æ¯”é‚£äº›å‡ ä¸‡è¡Œçš„æ¡†æ¶æ¸…çˆ½å¤šäº†ï¼Œä¹Ÿæœ‰äººæ€€ç–‘ 500 è¡Œèƒ½ä¸èƒ½ cover ä½å„ç§è¾¹ç•Œæƒ…å†µã€‚",
        ]
        
    elif 'container' in content_lower or 'docker' in content_lower:
        stories = [
            f"{opening}æä¾›äº†ä¸€å¥—åŠ å›ºè¿‡çš„å®¹å™¨é•œåƒï¼Œå®‰å…¨æ€§å’Œæ€§èƒ½éƒ½ç»è¿‡ä¼˜åŒ–ã€‚ä¸»è¦é¢å‘éœ€è¦é«˜å®‰å…¨æ€§å®¹å™¨ç¯å¢ƒçš„ä¼ä¸šç”¨æˆ·ï¼Œæ¯”å®˜æ–¹é•œåƒå‡å°‘äº†æ”»å‡»é¢ã€‚ç§»é™¤äº†ä¸å¿…è¦çš„ç³»ç»Ÿç»„ä»¶ã€å¯ç”¨äº†å„ç§å®‰å…¨åŠ å›ºé€‰é¡¹ã€å®šæœŸæ›´æ–°åŸºç¡€é•œåƒã€‚æ”¯æŒå¤šç§è¿è¡Œæ—¶ç¯å¢ƒï¼ŒåŒ…æ‹¬ Dockerã€containerdã€Podmanã€‚å¼€æºç¤¾åŒºå¯¹è¿™ç§åŠ å›ºé•œåƒçš„éœ€æ±‚æŒºå¤§ï¼Œç‰¹åˆ«æ˜¯é‡‘èå’ŒåŒ»ç–—è¡Œä¸šçš„ç”¨æˆ·ã€‚ç¼ºç‚¹æ˜¯é•œåƒä½“ç§¯æ¯”å®˜æ–¹ç‰ˆå¤§ä¸€äº›ï¼Œå¯åŠ¨æ—¶é—´ä¹Ÿç¨é•¿ã€‚",
            f"{opening}ç»™é‚£äº›å¯¹å®‰å…¨æ€§è¦æ±‚é«˜çš„ä¼ä¸šç”¨çš„ï¼Œæ¯”å®˜æ–¹é•œåƒç²¾ç®€äº†ä¸å°‘æ”»å‡»é¢ã€‚å»æ‰äº†ä¸å¿…è¦çš„ç³»ç»Ÿç»„ä»¶ï¼Œå¼€äº†å„ç§å®‰å…¨åŠ å›ºé€‰é¡¹ï¼ŒåŸºç¡€é•œåƒä¹Ÿå®šæœŸæ›´æ–°ã€‚æ”¯æŒ Dockerã€containerdã€Podman è¿™äº›è¿è¡Œæ—¶ã€‚é‡‘èå’ŒåŒ»ç–—è¡Œä¸šçš„ç”¨æˆ·æŒºéœ€è¦è¿™ç§çš„ï¼Œæ¯•ç«Ÿåˆè§„è¦æ±‚ä¸¥ã€‚ä»£ä»·å°±æ˜¯é•œåƒä½“ç§¯æ¯”å®˜æ–¹ç‰ˆå¤§ä¸€äº›ï¼Œå¯åŠ¨ä¹Ÿæ…¢ç‚¹ã€‚",
        ]
        
    elif 'github' in url.lower() and stars > 1000:
        stories = [
            f"{opening}GitHub ä¸Š {stars} star çš„å¼€æºé¡¹ç›®ï¼Œä¸»è¦ç”¨æ¥ {desc}ã€‚ä»£ç è´¨é‡åœ¨åŒç±»é¡¹ç›®é‡Œç®—ä¸é”™çš„ï¼ŒREADME æä¾›äº†å¿«é€Ÿå¼€å§‹ç¤ºä¾‹ï¼Œæœ‰åŸºç¡€çš„å¼€å‘è€…åº”è¯¥èƒ½æ¯”è¾ƒå¿«ä¸Šæ‰‹ã€‚ç”¨çš„äººä¸å°‘ï¼Œç¤¾åŒºè¿˜ç®—æ´»è·ƒï¼Œissue å“åº”é€Ÿåº¦ä¸€èˆ¬åœ¨ä¸€å‘¨å†…ã€‚å»ºè®®åœ¨æ­£å¼é¡¹ç›®é‡Œç”¨ä¹‹å‰å…ˆæ‹¿æµ‹è¯•æ•°æ®è·‘ä¸€éï¼Œç‰¹åˆ«æ˜¯çœ‹çœ‹åœ¨å¼‚å¸¸æƒ…å†µä¸‹è¡¨ç°å¦‚ä½•ï¼Œæ¯•ç«Ÿå¼€æºé¡¹ç›®ç»´æŠ¤ç²¾åŠ›æœ‰é™ã€‚",
            f"{opening}åœ¨ GitHub ä¸Šæ‹¿äº† {stars} starï¼Œåš {desc} çš„ã€‚ä»£ç è´¨é‡è¿˜å¯ä»¥ï¼ŒREADME æœ‰å¿«é€Ÿå¼€å§‹ï¼Œæœ‰ç‚¹åŸºç¡€çš„å¼€å‘è€…ä¸Šæ‰‹åº”è¯¥ä¸éš¾ã€‚ç”¨çš„äººæŒºå¤šï¼Œç¤¾åŒºæ´»è·ƒåº¦è¿˜è¡Œï¼Œissue ä¸€èˆ¬ä¸€å‘¨å†…æœ‰äººå›ã€‚å»ºè®®æ­£å¼ç”¨ä¹‹å‰å…ˆç”¨æµ‹è¯•æ•°æ®è·‘è·‘ï¼Œå°¤å…¶çœ‹çœ‹è¾¹ç•Œæƒ…å†µå¤„ç†å¾—æ€ä¹ˆæ ·ï¼Œå¼€æºé¡¹ç›®ç»´æŠ¤ç²¾åŠ›æ€»æ˜¯æœ‰é™çš„ã€‚",
        ]
        
    elif 'producthunt' in url.lower() and score > 50:
        stories = [
            f"{opening}ä»Šå¤©åˆšåœ¨ Product Hunt ä¸Šå‘å¸ƒï¼Œç›®å‰å·²ç»æ‹¿äº† {score} ä¸ª upvoteï¼Œè¡¨ç°ç›¸å½“ä¸é”™ã€‚å®ƒæ˜¯ä¸€ä¸ª {desc} çš„å·¥å…·ã€‚è¿™ä¸ªåˆ‡å…¥ç‚¹æŒºå‡†çš„ï¼Œä¹‹å‰å¸‚é¢ä¸Šè™½ç„¶æœ‰ä¸å°‘ç±»ä¼¼å·¥å…·ï¼Œä½†å¤§å¤šè¦ä¹ˆå¤ªå¤æ‚è¦ä¹ˆå¤ªè´µï¼Œå®ƒè¯•å›¾åœ¨ä¸­é—´æ‰¾ä¸€ä¸ªå¹³è¡¡ç‚¹ã€‚ä»é¡µé¢å±•ç¤ºçš„åŠŸèƒ½æ¥çœ‹ï¼Œæ ¸å¿ƒè§£å†³çš„æ˜¯ workflow è‡ªåŠ¨åŒ–çš„é—®é¢˜ã€‚æœ‰å…è´¹ tier å¯ä»¥è¯•ç”¨ï¼Œå»ºè®®å…ˆæ‹¿è‡ªå·±çš„æ•°æ®è·‘ä¸€éçœ‹çœ‹æ•ˆæœï¼Œåˆ«å…‰çœ‹ demoã€‚",
            f"{opening}ä»Šå¤©åœ¨ PH ä¸Šå‘å¸ƒäº†ï¼Œå·²ç»æ‹¿äº† {score} ä¸ª upvoteï¼Œåå“ä¸é”™ã€‚åš {desc} çš„ã€‚å¸‚åœºä¸ŠåŒç±»äº§å“è¦ä¹ˆåŠŸèƒ½å¤ªå¤æ‚ï¼Œè¦ä¹ˆå®šä»·å¤ªé«˜ï¼Œå®ƒå¡çš„ä½ç½®è¿˜æŒºå‡†çš„ã€‚çœ‹é¡µé¢ä»‹ç»ä¸»è¦æ˜¯è§£å†³ workflow è‡ªåŠ¨åŒ–çš„ç—›ç‚¹ã€‚æœ‰å…è´¹ç‰ˆå¯ä»¥è¯•ç”¨ï¼Œå»ºè®®åˆ«å…‰çœ‹ demoï¼Œæ‹¿è‡ªå·±çš„çœŸå®æ•°æ®è·‘ä¸€ä¸‹çœ‹çœ‹æ•ˆæœã€‚",
        ]
        
    else:
        stories = [
            f"{opening}æ˜¯ä¸€ä¸ª {desc} çš„é¡¹ç›®ã€‚{summary[:120] if summary else ''} æ²¡æœ‰è¯•å›¾åšå¤ªå¤šåŠŸèƒ½ï¼Œè€Œæ˜¯æŠŠæ ¸å¿ƒçš„ä¸€ç‚¹åšå¥½ã€‚{'ä»£ç å¼€æºåœ¨ GitHub ä¸Šï¼Œæœ‰å…´è¶£å®ç°ç»†èŠ‚çš„å¯ä»¥å»çœ‹çœ‹æºç ã€‚' if 'github' in url.lower() else 'åˆšå‘å¸ƒä¸ä¹…ï¼Œå»ºè®®å…ˆè§‚å¯Ÿä¸€ä¸¤ä¸ªæœˆçš„è¿­ä»£æƒ…å†µå†å†³å®šæ˜¯å¦æ·±åº¦ä½¿ç”¨ã€‚'}",
            f"{opening}åš {desc} çš„ã€‚{summary[:100] if summary else ''} åŠŸèƒ½ä¸Šæ¯”è¾ƒå…‹åˆ¶ï¼Œä¸“æ³¨åšå¥½ä¸€ä»¶äº‹ã€‚{'å¼€æºçš„ï¼Œä»£ç åœ¨ GitHub ä¸Šå¯ä»¥çœ‹åˆ°ã€‚' if 'github' in url.lower() else 'è¿˜å¤„åœ¨æ—©æœŸé˜¶æ®µï¼Œå¯ä»¥å…ˆè§‚æœ›ä¸€ä¸‹åç»­è¿­ä»£ã€‚'}",
        ]
    
    # é€‰æ‹©æ•…äº‹
    story_idx = (iteration + hash(url)) % len(stories)
    story = stories[story_idx]
    
    # æ£€æŸ¥æ˜¯å¦é‡å¤ï¼ˆç®€å•æ–‡æœ¬ç›¸ä¼¼åº¦ï¼‰
    story_hash = hash(story[:100])
    if story_hash in used_narratives:
        # å¦‚æœé‡å¤äº†ï¼Œé€‰å¦ä¸€ä¸ª
        story_idx = (story_idx + 1) % len(stories)
        story = stories[story_idx]
    
    used_narratives.add(story_hash)
    
    return story.strip() + f"\n\n{url}"

class StrictAutoDTP:
    """ä¸¥æ ¼è´¨é‡æ§åˆ¶çš„è‡ªåŠ¨DTP"""
    
    def __init__(self):
        self.iteration = 0
        self.webhook_url = self._get_webhook()
        self.sender = DiscordWebhookSender(self.webhook_url)
        self.published_contents = []
        
    def _get_webhook(self) -> str:
        url = os.getenv('DISCORD_WEBHOOK_URL')
        if not url:
            with open('.env', 'r') as f:
                for line in f:
                    if line.startswith('DISCORD_WEBHOOK_URL='):
                        url = line.strip().split('=', 1)[1]
                        break
        return url
    
    def develop(self, count: int = 10) -> List[Article]:
        """å¼€å‘é˜¶æ®µ"""
        print(f"\n{'='*60}")
        print(f"ğŸ”§ è¿­ä»£ {self.iteration}: ç”Ÿæˆ{count}æ¡")
        print('='*60)
        
        config = load_config()
        sources = create_sources(config.get("sources", {}))
        all_articles = []
        
        for source in sources:
            if source.is_enabled():
                try:
                    articles = source.fetch()
                    for a in articles:
                        a.metadata['collector_source'] = source.name
                    all_articles.extend(articles)
                    print(f"  âœ“ {source.name}: {len(articles)}æ¡")
                except Exception as e:
                    print(f"  âœ— {source.name}: {e}")
        
        # å»é‡
        dedup = ArticleDeduplicator()
        articles = dedup.filter_new_articles(all_articles)
        
        seen = set()
        unique = []
        for a in articles:
            if a.url and a.url not in seen:
                seen.add(a.url)
                unique.append(a)
        articles = unique
        
        print(f"ğŸ“Š æ”¶é›†{len(all_articles)}æ¡ï¼Œå»é‡å{len(articles)}æ¡")
        
        # æŒ‰åˆ†æ•°æ’åºåé€‰æ‹©
        scored = [(a, self._score(a)) for a in articles]
        scored.sort(key=lambda x: x[1], reverse=True)
        
        # å¼ºåˆ¶å¤šæ ·æ€§
        source_count = {}
        selected = []
        for article, score in scored:
            src = article.source
            if source_count.get(src, 0) < 3:
                selected.append(article)
                source_count[src] = source_count.get(src, 0) + 1
            if len(selected) >= count:
                break
        
        print(f"\nâ­ é€‰ä¸­{len(selected)}æ¡:")
        for src, cnt in sorted(source_count.items()):
            print(f"  â€¢ {src}: {cnt}æ¡")
        
        return selected
    
    def _score(self, article: Article) -> float:
        score = 0.0
        weights = {'producthunt': 1.5, 'twitter': 1.4, 'reddit': 1.2, 
                   'hackernews': 1.1, 'github_trending': 1.0, 'tavily': 0.9}
        score += weights.get(article.source, 0.5)
        meta = article.metadata or {}
        score += meta.get('score', 0) * 0.01
        score += meta.get('comments', 0) * 0.02
        return score
    
    def strict_review(self, articles: List[Article]) -> Tuple[bool, float, List[Dict]]:
        """ä¸¥æ ¼è¯„å®¡ - å‘ç°ç»“æ„åŒ–è¾“å‡ºç›´æ¥0åˆ†"""
        print(f"\n{'='*60}")
        print("ğŸ‘ï¸ ä¸¥æ ¼è´¨é‡è¯„å®¡ (ç»“æ„åŒ–=0åˆ†, é‡å¤=0åˆ†)")
        print('='*60)
        
        reviews = []
        contents = []
        
        for i, article in enumerate(articles, 1):
            content = generate_unique_narrative(article, self.iteration)
            
            # æ£€æŸ¥ç»“æ„åŒ–è¾“å‡º
            has_struct, struct_issues = self._check_structure(content)
            
            # æ£€æŸ¥ä¸å·²å‘å¸ƒå†…å®¹çš„é‡å¤
            has_duplicate, dup_issues = self._check_duplicate(content, self.published_contents)
            
            # è¯„åˆ†
            if has_struct or has_duplicate:
                score = 0.0
                issues = struct_issues + dup_issues
            else:
                # æ­£å¸¸è¯„åˆ†
                score = self._calculate_score(content, article)
                issues = []
            
            review = {
                'title': get_thread_title(article),
                'score': score,
                'content': content,
                'issues': issues,
                'passed': score >= SCORE_THRESHOLD
            }
            
            reviews.append(review)
            contents.append(review)
            
            status = "âœ…" if review['passed'] else "âŒ"
            print(f"\n  {i}. {status} {score:.1f}/10 {review['title'][:40]}...")
            if issues:
                print(f"     é—®é¢˜: {', '.join(issues[:2])}")
        
        avg_score = sum(r['score'] for r in reviews) / len(reviews) if reviews else 0
        passed = avg_score >= SCORE_THRESHOLD
        
        print(f"\nğŸ“Š å¹³å‡åˆ†: {avg_score:.1f}/10")
        print(f"{'âœ… é€šè¿‡' if passed else 'âŒ æœªé€šè¿‡'}")
        
        return passed, avg_score, contents
    
    def _check_structure(self, content: str) -> Tuple[bool, List[str]]:
        """æ£€æŸ¥ç»“æ„åŒ–è¾“å‡º"""
        import re
        patterns = [
            (r'ç¬¬ä¸€|ç¬¬äºŒ|ç¬¬ä¸‰|é¦–å…ˆ|å…¶æ¬¡|æœ€å', 'ä½¿ç”¨äº†åºå·'),
            (r'ã€|ã€‘', 'ä½¿ç”¨äº†ã€ã€‘ç¬¦å·'),
            (r'^[â€¢Â·-]\s', 'ä½¿ç”¨äº†åˆ—è¡¨ç¬¦å·'),
            (r'ä¸»è¦åŠŸèƒ½|ä½¿ç”¨åœºæ™¯|æŠ€æœ¯ç»†èŠ‚|ä¼˜ç¼ºç‚¹', 'ä½¿ç”¨äº†ç»“æ„åŒ–æ ‡é¢˜'),
            (r'ä».*æ¥çœ‹|ç»¼ä¸Šæ‰€è¿°|æ€»çš„æ¥è¯´', 'ä½¿ç”¨äº†ç©ºè¯å¥—è¯'),
            (r'é’ˆå¯¹ç—›ç‚¹|åŠŸèƒ½è®¾è®¡|è§£å†³æ–¹æ¡ˆ', 'ä½¿ç”¨äº†è¥é”€è¯æœ¯'),
        ]
        
        issues = []
        for pattern, desc in patterns:
            if re.search(pattern, content, re.MULTILINE):
                issues.append(desc)
        
        return len(issues) > 0, issues
    
    def _check_duplicate(self, content: str, published: List[str]) -> Tuple[bool, List[str]]:
        """æ£€æŸ¥å†…å®¹é‡å¤"""
        # ç®€å•ç›¸ä¼¼åº¦æ£€æŸ¥
        content_sig = content[:200]  # å–å‰200å­—ç¬¦ä½œä¸ºç‰¹å¾
        
        for pub in published:
            pub_sig = pub[:200] if isinstance(pub, str) else pub.get('content', '')[:200]
            # å¦‚æœå‰200å­—ç¬¦ç›¸ä¼¼åº¦è¶…è¿‡70%ï¼Œè®¤ä¸ºæ˜¯é‡å¤
            similarity = self._similarity(content_sig, pub_sig)
            if similarity > 0.7:
                return True, [f"ä¸å·²å‘å¸ƒå†…å®¹é‡å¤ (ç›¸ä¼¼åº¦{similarity:.0%})"]
        
        return False, []
    
    def _similarity(self, s1: str, s2: str) -> float:
        """è®¡ç®—ç®€å•ç›¸ä¼¼åº¦"""
        if not s1 or not s2:
            return 0.0
        
        # ä½¿ç”¨ç®€å•çš„è¯é›†åˆäº¤é›†
        words1 = set(s1.lower().split())
        words2 = set(s2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1 & words2
        union = words1 | words2
        
        return len(intersection) / len(union) if union else 0.0
    
    def _calculate_score(self, content: str, article: Article) -> float:
        """è®¡ç®—å†…å®¹è´¨é‡åˆ†"""
        score = 10.0
        
        # å­—æ•°æ£€æŸ¥
        word_count = len(content.replace(' ', '').replace('\n', ''))
        if word_count < 200:
            score -= 2
        elif word_count > 800:
            score -= 1
        
        # ä¿¡æ¯å¯†åº¦
        has_numbers = any(c.isdigit() for c in content)
        if not has_numbers:
            score -= 1
        
        has_tech = any(kw in content.lower() for kw in ['ä½¿ç”¨', 'åŸºäº', 'ä»£ç ', 'æŠ€æœ¯'])
        if not has_tech:
            score -= 1
        
        has_usage = any(kw in content.lower() for kw in ['é€‚åˆ', 'å¯ä»¥', 'ç”¨æ¥'])
        if not has_usage:
            score -= 1
        
        return max(0, score)
    
    def deploy(self, contents: List[Dict]):
        """å‘å¸ƒåˆ°Discord"""
        print(f"\n{'='*60}")
        print("ğŸš€ å‘å¸ƒåˆ°Discord")
        print('='*60)
        
        # ç­›é€‰é«˜åˆ†å†…å®¹
        high_score = [c for c in contents if c.get('score', 0) >= SCORE_THRESHOLD]
        if not high_score:
            high_score = contents[:5]
        
        print(f"\nå‘å¸ƒ{len(high_score)}æ¡:")
        for i, c in enumerate(high_score, 1):
            print(f"  {i}. {c['title'][:40]}... ({c['score']:.1f}åˆ†)")
            self.sender.send_to_forum(c['title'], c['content'])
            self.published_contents.append(c['content'])
            time.sleep(2)
        
        print(f"\nâœ… å‘å¸ƒå®Œæˆ")
    
    def run(self):
        """è¿è¡Œå®Œæ•´é—­ç¯"""
        print("\n" + "="*60)
        print("ğŸ¯ AiTrend ä¸¥æ ¼DTPé—­ç¯ (ç»“æ„åŒ–=0åˆ†)")
        print("="*60)
        print(f"é…ç½®: {ARTICLE_COUNT}æ¡ | é˜ˆå€¼{SCORE_THRESHOLD}åˆ† | æœ€å¤š{MAX_ITERATIONS}è½®")
        
        for iteration in range(1, MAX_ITERATIONS + 1):
            self.iteration = iteration
            
            # DEVELOP
            articles = self.develop(count=ARTICLE_COUNT)
            
            # REVIEW
            passed, score, contents = self.strict_review(articles)
            
            # DEPLOY if passed
            if passed:
                print(f"\nâœ… è¾¾æ ‡ï¼å‘å¸ƒå†…å®¹...")
                self.deploy(contents)
                print("\n" + "="*60)
                print("âœ… DTPæˆåŠŸå®Œæˆï¼æ‰€æœ‰å†…å®¹å·²è¾¾æ ‡")
                print("="*60)
                return True
            
            if iteration < MAX_ITERATIONS:
                print(f"\nğŸ”„ æœªè¾¾æ ‡ï¼Œé‡æ–°ç”Ÿæˆ...")
                time.sleep(3)
            else:
                print(f"\nâš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£ï¼Œå‘å¸ƒæœ€é«˜åˆ†å†…å®¹...")
                self.deploy(contents)
                return False

def main():
    controller = StrictAutoDTP()
    success = controller.run()
    
    print("\n" + "="*60)
    if success:
        print("âœ… æ‰€æœ‰å†…å®¹å·²è¾¾æ ‡å¹¶é€šè¿‡ä¸¥æ ¼è´¨é‡æ£€æŸ¥")
    else:
        print("âš ï¸ æµç¨‹å®Œæˆï¼ˆéƒ¨åˆ†æœªå®Œå…¨è¾¾æ ‡ï¼‰")
    print("="*60)

if __name__ == '__main__':
    main()
