#!/usr/bin/env python3
"""
AiTrend æ¯å°æ—¶å•æ¡å‘å¸ƒæ¨¡å¼
é€‰æ‹©æœ€çƒ­é—¨çš„1æ¡AIèµ„è®¯ï¼Œä»¥å£è¯­åŒ–æ–¹å¼å‘å¸ƒåˆ°è®ºå›
"""

import json
import sys
import os
import random
from datetime import datetime
from typing import List, Dict, Any

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.sources import create_sources
from src.sources.base import Article
from src.core.deduplicator import ArticleDeduplicator
from src.core.config_loader import load_config
from src.core.webhook_sender import DiscordWebhookSender

def collect_all_sources(config: Dict[str, Any]) -> List[Article]:
    """ä»æ‰€æœ‰æ•°æ®æºæ”¶é›†æ–‡ç« """
    sources_config = config.get("sources", {})
    sources = create_sources(sources_config)
    
    all_articles = []
    for source in sources:
        if source.is_enabled():
            try:
                articles = source.fetch()
                # æ ‡è®°æ¥æº
                for article in articles:
                    article.metadata['collector_source'] = source.name
                all_articles.extend(articles)
                print(f"âœ“ {source.name}: {len(articles)} æ¡", file=sys.stderr)
            except Exception as e:
                print(f"âœ— {source.name}: {e}", file=sys.stderr)
    
    return all_articles

def calculate_hot_score(article: Article) -> float:
    """è®¡ç®—çƒ­åº¦åˆ†æ•°"""
    score = 0.0
    
    # åŸºç¡€åˆ†ï¼šæ ¹æ®æ¥æºæƒé‡
    source_weights = {
        'producthunt': 1.5,  # æ–°äº§å“ä¼˜å…ˆçº§é«˜
        'twitter': 1.4,
        'reddit': 1.2,
        'hackernews': 1.1,
        'github_trending': 1.0,
        'tavily': 0.9
    }
    score += source_weights.get(article.source, 0.5)
    
    # äº’åŠ¨åˆ†
    metadata = article.metadata or {}
    score += metadata.get('score', 0) * 0.01  # HN/Reddit åˆ†æ•°
    score += metadata.get('comments', 0) * 0.02  # è¯„è®ºæƒé‡æ›´é«˜
    score += metadata.get('upvotes', 0) * 0.01
    
    # æ—¶æ•ˆæ€§ï¼šè¶Šæ–°è¶Šå¥½
    try:
        if 'published_at' in metadata:
            pub_time = datetime.fromisoformat(metadata['published_at'].replace('Z', '+00:00'))
            hours_ago = (datetime.now(pub_time.tzinfo) - pub_time).total_seconds() / 3600
            if hours_ago < 1:
                score += 2.0  # 1å°æ—¶å†… +2åˆ†
            elif hours_ago < 6:
                score += 1.0  # 6å°æ—¶å†… +1åˆ†
            elif hours_ago < 24:
                score += 0.5  # 24å°æ—¶å†… +0.5åˆ†
    except:
        pass
    
    return score

def select_best_article(articles: List[Article]) -> Article:
    """é€‰æ‹©æœ€çƒ­é—¨çš„å•æ¡"""
    # è®¡ç®—æ¯æ¡çš„çƒ­åº¦
    scored_articles = [(article, calculate_hot_score(article)) for article in articles]
    
    # æŒ‰åˆ†æ•°æ’åº
    scored_articles.sort(key=lambda x: x[1], reverse=True)
    
    # è¿”å›æœ€é«˜åˆ†
    return scored_articles[0][0] if scored_articles else None

def format_casual_content(article: Article) -> str:
    """æ ¼å¼åŒ–ä¸ºå£è¯­åŒ–å†…å®¹"""
    date_str = datetime.now().strftime('%m-%d')
    hour_str = datetime.now().strftime('%H:%M')
    
    # å£è¯­åŒ–å¼€åœº
    openings = [
        f"åˆšåˆšå‘ç°ä¸ªæœ‰æ„æ€çš„ï¼{article.title}",
        f"è¿™ä¸ªæŒºç«çš„ï¼Œ{article.title}",
        f"å„ä½çœ‹çœ‹è¿™ä¸ªï½ {article.title}",
        f"æ–°é²œå‡ºç‚‰ï¼{article.title}",
        f"è¿™ä¸ªå€¼å¾—å…³æ³¨ï¼š{article.title}",
    ]
    
    opening = random.choice(openings)
    
    # æ­£æ–‡æè¿°ï¼ˆå£è¯­åŒ–ï¼‰
    summary = article.summary or ""
    if len(summary) > 400:
        summary = summary[:400] + "..."
    
    # æ„å»ºå†…å®¹
    lines = [
        f"ğŸ”¥ **{opening}**",
        "",
        summary,
        "",
        f"ğŸ”— {article.url}",
        f"ğŸ“Œ æ¥è‡ª {article.source}",
        "",
        f"_å‘å¸ƒæ—¶é—´ï¼š{hour_str} | AiTrend æ¯å°æ—¶ç²¾é€‰_"
    ]
    
    return "\n".join(lines)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ AiTrend æ¯å°æ—¶ç²¾é€‰æ¨¡å¼", file=sys.stderr)
    
    # åŠ è½½é…ç½®
    try:
        config = load_config()
    except FileNotFoundError as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)
    
    # æ”¶é›†æ•°æ®
    print("\nğŸ“¡ æ­£åœ¨æ”¶é›†å„æ•°æ®æº...", file=sys.stderr)
    all_articles = collect_all_sources(config)
    print(f"\nğŸ“Š å…±æ”¶é›† {len(all_articles)} æ¡", file=sys.stderr)
    
    if not all_articles:
        print("âš ï¸ æ— æ•°æ®ï¼Œè·³è¿‡æœ¬æ¬¡", file=sys.stderr)
        sys.exit(0)
    
    # å»é‡
    deduplicator = ArticleDeduplicator()
    articles = deduplicator.filter_new_articles(all_articles)
    
    # è¿‡æ»¤ï¼š24å°æ—¶å†…å·²å‘çš„ä¸é‡å¤
    seen_urls = set()
    unique_articles = []
    for article in articles:
        if article.url and article.url not in seen_urls:
            seen_urls.add(article.url)
            unique_articles.append(article)
    articles = unique_articles
    
    print(f"ğŸ” å»é‡å: {len(articles)} æ¡", file=sys.stderr)
    
    if not articles:
        print("âš ï¸ æ— æ–°å†…å®¹ï¼Œè·³è¿‡æœ¬æ¬¡", file=sys.stderr)
        sys.exit(0)
    
    # é€‰æ‹©æœ€çƒ­é—¨çš„ä¸€æ¡
    best_article = select_best_article(articles)
    
    if not best_article:
        print("âš ï¸ æ— æ³•é€‰æ‹©æœ€ä½³æ–‡ç« ", file=sys.stderr)
        sys.exit(1)
    
    print(f"\nâ­ é€‰ä¸­: {best_article.title}", file=sys.stderr)
    print(f"   æ¥æº: {best_article.source}", file=sys.stderr)
    
    # è®°å½•å·²å‘é€
    deduplicator.record_sent_articles([best_article])
    
    # æ ¼å¼åŒ–å†…å®¹
    content = format_casual_content(best_article)
    
    # è·å– Webhook URL
    webhook_url = os.getenv('DISCORD_WEBHOOK_URL')
    if not webhook_url:
        with open('.env', 'r') as f:
            for line in f:
                if line.startswith('DISCORD_WEBHOOK_URL='):
                    webhook_url = line.strip().split('=', 1)[1]
                    break
    
    # å‘å¸ƒåˆ°è®ºå›
    print(f"\nğŸ“¤ æ­£åœ¨å‘å¸ƒåˆ°è®ºå›...", file=sys.stderr)
    sender = DiscordWebhookSender(webhook_url)
    
    date_str = datetime.now().strftime('%m-%d')
    hour_str = datetime.now().strftime('%H:%M')
    thread_title = f"ğŸ”¥ {hour_str} AI çƒ­ç‚¹"
    
    result = sender.send_to_forum(thread_title, content)
    
    if result:
        print(f"âœ… æˆåŠŸå‘å¸ƒï¼", file=sys.stderr)
        # è¾“å‡ºJSONä¾›è°ƒç”¨è€…ä½¿ç”¨
        output = {
            "success": True,
            "title": best_article.title,
            "source": best_article.source,
            "url": best_article.url,
            "published_at": f"{date_str} {hour_str}"
        }
        print(json.dumps(output, ensure_ascii=False))
    else:
        print(f"âŒ å‘å¸ƒå¤±è´¥", file=sys.stderr)
        sys.exit(1)

if __name__ == '__main__':
    main()
