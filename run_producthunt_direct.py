#!/usr/bin/env python3
"""
Product Hunt æµç¨‹ - ç›´æ¥å‘å¸ƒåˆ°è®ºå›
ç¦æ­¢ç»“æ„åŒ–æè¿°ï¼Œé¿å…é‡å¤å¼€å¤´
"""

import os
import sys
import json
import time
from typing import List, Dict, Any

sys.path.insert(0, '.')

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = '.env'
if os.path.exists(env_path):
    with open(env_path, 'r') as f:
        for line in f:
            if '=' in line and not line.startswith('#'):
                key, value = line.strip().split('=', 1)
                os.environ[key] = value

from modules.logger import get_logger
from publishers import create_publisher

logger = get_logger()

def fetch_from_producthunt() -> List[Dict]:
    """ä» Product Hunt è·å–äº§å“"""
    logger.section("ğŸ“¡ ä» Product Hunt æŒ–æ˜äº§å“")
    
    from modules.sources.producthunt import Producthunt
    
    config = {
        'categories': ['AI', 'Developer Tools', 'Productivity'],
        'min_votes': 50,
        'time_period': 'daily',
        'max_candidates': 5
    }
    
    source = Producthunt(config)
    
    if not source.is_enabled():
        logger.error("âŒ Product Hunt æ¨¡å—æœªå¯ç”¨")
        return []
    
    candidates = source.discover()
    
    for c in candidates:
        c['source_name'] = 'Product Hunt'
    
    return candidates

def generate_with_llm(candidate: Dict, index: int) -> str:
    """ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆå†…å®¹ - ç¦æ­¢ç»“æ„åŒ–"""
    name = candidate.get('name', '')
    tagline = candidate.get('tagline', '')
    description = candidate.get('description', '')
    votes = candidate.get('votes', 0)
    url = candidate.get('url', '')
    makers = candidate.get('makers', [])
    
    logger.info(f"ğŸ“ ç”Ÿæˆå†…å®¹: {name}")
    
    # æ„å»ºä¸Šä¸‹æ–‡
    context_parts = []
    
    if name:
        context_parts.append(f"äº§å“å: {name}")
    
    if tagline:
        context_parts.append(f" Slogan: {tagline}")
    
    if description:
        context_parts.append(f"ä»‹ç»: {description[:400]}")
    
    if votes:
        context_parts.append(f"æŠ•ç¥¨: {votes}")
    
    if makers:
        context_parts.append(f"å›¢é˜Ÿ: {', '.join(makers[:2])}")
    
    context = "\n".join(context_parts)
    
    # å¼€å¤´å¤šæ ·åŒ–æç¤º
    opening_styles = [
        "ç›´æ¥åˆ‡å…¥äº§å“",
        "ä»äº§å“è§£å†³çš„é—®é¢˜åˆ‡å…¥", 
        "ä»ä½¿ç”¨åœºæ™¯åˆ‡å…¥",
        "ä»ç‹¬ç‰¹ä¹‹å¤„åˆ‡å…¥",
        "ä»å¯¹æ¯”ä¼ ç»Ÿæ–¹å¼åˆ‡å…¥"
    ]
    
    style = opening_styles[index % len(opening_styles)]
    
    task = f"""å†™ä¸€æ®µäº§å“ä»‹ç»ï¼ŒåŸºäºä»¥ä¸‹ä¿¡æ¯ï¼š

{context}

æ ¸å¿ƒè¦æ±‚ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
1. âŒ ç¦æ­¢å¼€å¤´ç”¨"æœ€è¿‘å‘ç°"ã€"ä»Šå¤©çœ‹åˆ°"ã€"æˆ‘æ‰¾åˆ°ä¸€ä¸ª"ç­‰å¥—è¯
2. âŒ ç¦æ­¢ç”¨ç¬¬ä¸€ç¬¬äºŒã€é¦–å…ˆå…¶æ¬¡ç­‰åºå·
3. âŒ ç¦æ­¢ç”¨åˆ—è¡¨ç¬¦å·ï¼ˆ- * â€¢ï¼‰
4. âŒ ç¦æ­¢é‡å¤ç”¨è¯å’Œå¥å¼ï¼ˆé‡å¤æ€§æƒ©ç½šï¼‰
5. âŒ ç¦æ­¢ç©ºè¯ï¼š"é’ˆå¯¹ç—›ç‚¹"ã€"åŠŸèƒ½è®¾è®¡"ã€"æ¶æ„æ¸…æ™°"ã€"æ—¨åœ¨è§£å†³"
6. âœ… ç›´æ¥æè¿°äº§å“æ˜¯ä»€ä¹ˆã€èƒ½åšä»€ä¹ˆã€ä¸ºä»€ä¹ˆå€¼å¾—ç”¨
7. âœ… è¿ç»­æ®µè½ï¼Œæµç•…è‡ªç„¶
8. âœ… æ§åˆ¶åœ¨300å­—ä»¥å†…
9. âœ… æœ€åå¿…é¡»åŒ…å«é“¾æ¥: {url}

å¼€å¤´é£æ ¼æç¤º: ä½¿ç”¨"{style}"çš„æ–¹å¼å¼€å¤´"""
    
    # ä½¿ç”¨ subprocess è°ƒç”¨ OpenClaw
    import subprocess
    import tempfile
    
    # å†™å…¥ä»»åŠ¡æ–‡ä»¶
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
        f.write(task)
        task_file = f.name
    
    # å†™å…¥è¾“å‡ºæ–‡ä»¶
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
        output_file = f.name
    
    # åˆ›å»ºè„šæœ¬è°ƒç”¨ sessions_spawn
    script_content = f'''
import sys
sys.path.insert(0, '.')

with open("{task_file}", "r", encoding="utf-8") as f:
    task = f.read()

from tools import sessions_spawn

result = sessions_spawn(task=task, timeout_seconds=120)

with open("{output_file}", "w", encoding="utf-8") as f:
    f.write(result if result else "")

print("Done")
'''
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False, encoding='utf-8') as f:
        f.write(script_content)
        script_file = f.name
    
    # æ‰§è¡Œ
    try:
        result = subprocess.run(
            ['python3', script_file],
            capture_output=True,
            text=True,
            timeout=180,
            cwd='/home/ubuntu/.openclaw/workspace/AiTrend'
        )
        
        # è¯»å–è¾“å‡º
        content = ""
        if os.path.exists(output_file):
            with open(output_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
        
        # æ¸…ç†
        for f in [task_file, output_file, script_file]:
            try:
                if os.path.exists(f):
                    os.unlink(f)
            except:
                pass
        
        if content:
            # ç¡®ä¿é“¾æ¥åœ¨å†…å®¹ä¸­
            if url not in content:
                content = content.strip() + f"\n\n{url}"
            
            logger.info(f"   âœ… ç”ŸæˆæˆåŠŸ ({len(content)} å­—ç¬¦)")
            return content
        else:
            logger.error(f"   âŒ ç”Ÿæˆå¤±è´¥: æ— è¾“å‡º")
            return ""
            
    except Exception as e:
        logger.error(f"   âŒ ç”Ÿæˆå¤±è´¥: {e}")
        return ""

def publish_contents(contents: List[Dict]) -> int:
    """ç›´æ¥å‘å¸ƒåˆ° Discord è®ºå›"""
    logger.section("ğŸ“¤ ç›´æ¥å‘å¸ƒåˆ° Discord è®ºå›")
    
    config = {
        'webhook_url': os.getenv('DISCORD_WEBHOOK_URL'),
        'thread_name': '{name} â€“ {source}',
        'username': 'AiTrend',
        'delay': 2
    }
    
    publisher = create_publisher('forum', config)
    
    if not publisher:
        logger.error("âŒ åˆ›å»ºå‘å¸ƒæ¨¡å—å¤±è´¥")
        return 0
    
    # éªŒè¯é“¾æ¥
    for content in contents:
        url = content.get('url', '')
        text = content.get('content', '')
        if url and url not in text:
            content['content'] = text.strip() + f"\n\n{url}"
    
    return publisher.publish_batch(contents)

def main():
    """ä¸»æµç¨‹"""
    logger.section("ğŸ¯ Product Hunt ç›´æ¥å‘å¸ƒæµç¨‹")
    
    # 1. è·å–äº§å“
    candidates = fetch_from_producthunt()
    
    if not candidates:
        logger.error("âŒ æœªè·å–åˆ°äº§å“")
        return
    
    # 2. ç”Ÿæˆå†…å®¹ï¼ˆå‰3ä¸ªï¼‰
    logger.section("ğŸ“ ç”Ÿæˆå†…å®¹ï¼ˆç¦æ­¢ç»“æ„åŒ–æè¿°ï¼‰")
    
    generated_contents = []
    for i, candidate in enumerate(candidates[:3], 1):
        content_text = generate_with_llm(candidate, i-1)  # ä¼ é€’ç´¢å¼•ç”¨äºå¤šæ ·åŒ–å¼€å¤´
        if content_text:
            generated_contents.append({
                'name': candidate.get('name', ''),
                'content': content_text,
                'url': candidate.get('url', ''),
                'source': 'Product Hunt'
            })
        time.sleep(2)
    
    logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(generated_contents)} æ¡å†…å®¹")
    
    # 3. ç›´æ¥å‘å¸ƒåˆ°è®ºå›ï¼ˆä¸å‘é€åˆ°å½“å‰å¯¹è¯ï¼‰
    if generated_contents:
        published = publish_contents(generated_contents)
        logger.section(f"âœ… æµç¨‹å®Œæˆï¼å·²å‘å¸ƒ {published} æ¡åˆ°è®ºå›")
    else:
        logger.warning("âš ï¸ æ²¡æœ‰å†…å®¹å¯å‘å¸ƒ")

if __name__ == '__main__':
    main()
