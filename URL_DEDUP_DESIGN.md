# URL å»é‡å®Œç¾æ–¹æ¡ˆè®¾è®¡

## é—®é¢˜åˆ†æ

### çŸ›ç›¾ç‚¹
- **æƒ…å†µA**: `?srsltid=xxx` â†’ åŒä¸€ç¯‡æ–‡ç« ï¼Œåº”è¯¥å»é‡ âœ…
- **æƒ…å†µB**: `?id=123` vs `?id=456` â†’ ä¸åŒæ–‡ç« ï¼Œåº”è¯¥ä¿ç•™ âŒ
- **æƒ…å†µC**: `?page=1` vs `?page=2` â†’ ä¸åŒå†…å®¹ï¼Œåº”è¯¥ä¿ç•™ âŒ

### æ ¸å¿ƒæŒ‘æˆ˜
å¦‚ä½•åŒºåˆ† **è·Ÿè¸ªå‚æ•°** vs **å†…å®¹å‚æ•°**ï¼Ÿ

---

## å®Œç¾æ–¹æ¡ˆï¼šå¤šå±‚é˜²å¾¡ä½“ç³»

### ç¬¬ä¸€å±‚ï¼šæ™ºèƒ½å‚æ•°è¯†åˆ«ï¼ˆç™½åå•ï¼‰

```python
# åªç§»é™¤å·²çŸ¥çš„"çº¯è·Ÿè¸ªå‚æ•°"
TRACKING_PARAMS = {
    # å¹¿å‘Š/åˆ†æè·Ÿè¸ª
    'utm_source', 'utm_medium', 'utm_campaign', 'utm_term', 'utm_content',
    'gclid', 'fbclid', 'msclkid', 'dclid', 'zanpid', 'kenshoo',
    
    # ç¤¾äº¤åª’ä½“è·Ÿè¸ª
    'srsltid',  # Google
    'si', 'igshid', 'ttclid',  # TikTok/Instagram
    'twclid', 'li_fat_id',  # Twitter/LinkedIn
    
    # é‚®ä»¶/æ¨å¹¿è·Ÿè¸ª
    'mc_cid', 'mc_eid',  # Mailchimp
    'yclid', 'cid', 'ecid',
    'ref', 'referrer', 'referral_code',
    
    # A/Bæµ‹è¯•
    'variant', 'ab_test', 'exp_id',
}

# ä¿ç•™çš„"å†…å®¹å‚æ•°"ï¼ˆç™½åå•ï¼‰
CONTENT_PARAMS = {
    'id', 'post', 'article', 'p', 'story',
    'page', 'offset', 'cursor', 'next',
    'category', 'tag', 'topic', 'channel',
    'user', 'author', 'u',
    'v', 'version', 'rev',
    'lang', 'locale', 'l',
    'format', 'type', 't',
}
```

### ç¬¬äºŒå±‚ï¼šè·¯å¾„ä¼˜å…ˆç­–ç•¥

```python
def get_url_signature(url: str) -> str:
    """
    ç”Ÿæˆ URL ç­¾åç”¨äºå»é‡
    ç­–ç•¥ï¼šè·¯å¾„ä¼˜å…ˆï¼Œå‚æ•°æ¬¡ä¹‹
    """
    parsed = urlparse(url)
    
    # 1. åŸºç¡€è·¯å¾„ï¼ˆæœ€é‡è¦ï¼‰
    base_path = parsed.path.rstrip('/')
    
    # 2. ä¿ç•™å†…å®¹å‚æ•°ï¼Œç§»é™¤è·Ÿè¸ªå‚æ•°
    query_params = parse_qsl(parsed.query)
    content_params = [
        f"{k}={v}" for k, v in query_params
        if k.lower() not in TRACKING_PARAMS
    ]
    
    # 3. ç”Ÿæˆç­¾å
    if content_params:
        return f"{base_path}?{'&'.join(sorted(content_params))}"
    return base_path
```

### ç¬¬ä¸‰å±‚ï¼šå†…å®¹æŒ‡çº¹å…œåº•

```python
import hashlib

def content_fingerprint(title: str, summary: str = "") -> str:
    """
    åŸºäºå†…å®¹çš„æŒ‡çº¹
    å³ä½¿ URL ä¸åŒï¼Œç›¸åŒå†…å®¹ä¹Ÿèƒ½è¯†åˆ«
    """
    # æå–å…³é”®è¯ï¼ˆæ ‡é¢˜å‰50å­— + æ‘˜è¦å‰100å­—ï¼‰
    text = (title[:50] + summary[:100]).lower()
    
    # ç§»é™¤å¸¸è§å™ªéŸ³è¯
    noise_words = {'the', 'a', 'an', 'in', 'on', 'at', 'to', 'for'}
    words = [w for w in re.findall(r'\b\w+\b', text) 
             if w not in noise_words and len(w) > 2]
    
    # æ’åºåç”ŸæˆæŒ‡çº¹ï¼ˆç¡®ä¿ç›¸åŒå…³é”®è¯ä¸åŒé¡ºåºä¹Ÿå¾—åˆ°ç›¸åŒæŒ‡çº¹ï¼‰
    fingerprint_text = ''.join(sorted(words))
    return hashlib.sha256(fingerprint_text.encode()).hexdigest()[:16]
```

### ç¬¬å››å±‚ï¼šåŸŸåç‰¹å®šè§„åˆ™

```python
DOMAIN_RULES = {
    # æ–°é—»åª’ä½“ï¼šé€šå¸¸ ID å‚æ•°æ˜¯å†…å®¹æ ‡è¯†
    'techcrunch.com': {'keep_params': ['id', 'guccounter']},
    'medium.com': {'keep_params': []},  # Medium è·¯å¾„å³ ID
    
    # è®ºå›ï¼šå¯èƒ½ç”¨ ?t=123 è¡¨ç¤ºå¸–å­
    'news.ycombinator.com': {'keep_params': ['id']},
    
    # ç”µå•†ï¼šéœ€è¦ä¿ç•™å•†å“ ID
    'amazon.com': {'keep_params': ['dp', 'asin']},
    'producthunt.com': {'keep_params': ['utm_campaign']},  # PH ç”¨ utm ä½œä¸ºäº§å“æ ‡è¯†
    
    # é»˜è®¤è§„åˆ™
    'default': {'keep_params': ['id', 'post', 'p', 'article']}
}
```

### ç¬¬äº”å±‚ï¼šç›¸ä¼¼åº¦æ£€æµ‹

```python
from difflib import SequenceMatcher

def url_similarity(url1: str, url2: str) -> float:
    """
    è®¡ç®—ä¸¤ä¸ª URL çš„ç›¸ä¼¼åº¦
    ç”¨äºæ£€æµ‹ç»†å¾®å·®å¼‚çš„é‡å¤
    """
    # è§„èŒƒåŒ–åæ¯”è¾ƒ
    sig1 = get_url_signature(url1)
    sig2 = get_url_signature(url2)
    
    return SequenceMatcher(None, sig1, sig2).ratio()

# ä½¿ç”¨ï¼šç›¸ä¼¼åº¦ > 0.9 è®¤ä¸ºæ˜¯åŒä¸€ç¯‡æ–‡ç« 
def is_likely_duplicate(url1: str, url2: str) -> bool:
    return url_similarity(url1, url2) > 0.9
```

---

## å®Œæ•´å®ç°ä»£ç 

```python
class SmartDeduplicator:
    """æ™ºèƒ½å»é‡å™¨ - å®Œç¾å…¼å®¹å„ç±» URL"""
    
    def __init__(self, memory_path: str = None):
        self.memory_path = memory_path
        self.window_hours = 24
        
        # åŠ è½½é…ç½®
        self.config = self._load_config()
    
    def is_duplicate(self, article: Article) -> bool:
        """
        å¤šå±‚æ£€æµ‹æ˜¯å¦æ˜¯é‡å¤æ–‡ç« 
        åªè¦æ»¡è¶³ä»»ä¸€æ¡ä»¶å³è®¤ä¸ºæ˜¯é‡å¤
        """
        url = article.url
        title = article.title
        summary = article.summary
        
        # ç¬¬ä¸€å±‚ï¼šURL ç­¾ååŒ¹é…
        url_sig = self._get_url_signature(url)
        if self._check_signature_exists(url_sig):
            return True
        
        # ç¬¬äºŒå±‚ï¼šå†…å®¹æŒ‡çº¹åŒ¹é…
        content_fp = content_fingerprint(title, summary)
        if self._check_fingerprint_exists(content_fp):
            return True
        
        # ç¬¬ä¸‰å±‚ï¼šURL ç›¸ä¼¼åº¦æ£€æµ‹
        if self._check_similar_url_exists(url):
            return True
        
        return False
    
    def _get_url_signature(self, url: str) -> str:
        """è·å– URL ç­¾åï¼ˆç§»é™¤äº†è·Ÿè¸ªå‚æ•°ï¼‰"""
        parsed = urlparse(url)
        domain = parsed.netloc.lower()
        
        # è·å–åŸŸåç‰¹å®šè§„åˆ™
        domain_rule = self.DOMAIN_RULES.get(domain, self.DOMAIN_RULES['default'])
        keep_params = set(domain_rule.get('keep_params', []))
        
        # æ„å»ºç­¾å
        base_path = parsed.path.rstrip('/')
        query_params = parse_qsl(parsed.query)
        
        # ä¿ç•™å†…å®¹å‚æ•° + åŸŸåç‰¹å®šå‚æ•°
        filtered = []
        for k, v in query_params:
            k_lower = k.lower()
            if k_lower in keep_params or k_lower in self.CONTENT_PARAMS:
                filtered.append(f"{k}={v}")
        
        if filtered:
            return f"{domain}{base_path}?{'&'.join(sorted(filtered))}"
        return f"{domain}{base_path}"
```

---

## é…ç½®ç¤ºä¾‹

```yaml
deduplication:
  # åŸºç¡€é…ç½®
  window_hours: 24
  
  # URL ç­¾åé…ç½®
  url_signature:
    # è¦ç§»é™¤çš„è·Ÿè¸ªå‚æ•°
    remove_params:
      - utm_*
      - gclid
      - fbclid
      - srsltid
    
    # è¦ä¿ç•™çš„å†…å®¹å‚æ•°
    keep_params:
      - id
      - post
      - article
      - p
  
  # å†…å®¹æŒ‡çº¹é…ç½®
  content_fingerprint:
    enabled: true
    title_weight: 0.6
    summary_weight: 0.4
    min_content_length: 50
  
  # ç›¸ä¼¼åº¦æ£€æµ‹é…ç½®
  similarity:
    enabled: true
    threshold: 0.9  # 90% ç›¸ä¼¼åº¦è®¤ä¸ºæ˜¯é‡å¤
  
  # åŸŸåç‰¹å®šè§„åˆ™
  domain_rules:
    "medium.com":
      ignore_params: true  # Medium åªç”¨è·¯å¾„
    
    "producthunt.com":
      keep_params:
        - utm_campaign  # PH ç”¨è¿™ä¸ªæ ‡è¯†äº§å“
```

---

## é¢„æœŸæ•ˆæœ

| åœºæ™¯ | æ—§æ–¹æ¡ˆ | æ–°æ–¹æ¡ˆ |
|------|--------|--------|
| vertu.com/?srsltid=xxx | âŒ 9æ¬¡é‡å¤ | âœ… 1æ¬¡ |
| example.com/?id=123 vs ?id=456 | âŒ å¯èƒ½è¯¯åˆ  | âœ… æ­£ç¡®ä¿ç•™ |
| example.com/?page=1 vs ?page=2 | âŒ å¯èƒ½è¯¯åˆ  | âœ… æ­£ç¡®ä¿ç•™ |
| ä¸åŒ URL ç›¸åŒæ ‡é¢˜ | âŒ æ¼æ£€ | âœ… æŒ‡çº¹æ£€æµ‹ |
| ç»†å¾® URL å·®å¼‚ | âŒ æ¼æ£€ | âœ… ç›¸ä¼¼åº¦æ£€æµ‹ |

---

## å®æ–½å»ºè®®

### Phase 1: ç«‹å³å®æ–½ï¼ˆå·²éƒ¨åˆ†å®Œæˆï¼‰
- âœ… ç™½åå•è·Ÿè¸ªå‚æ•°ç§»é™¤
- â³ æ·»åŠ è·¯å¾„ä¼˜å…ˆç­–ç•¥

### Phase 2: å¢å¼ºç‰ˆï¼ˆæœ¬å‘¨ï¼‰
- æ·»åŠ å†…å®¹æŒ‡çº¹
- æ·»åŠ ç›¸ä¼¼åº¦æ£€æµ‹
- æ·»åŠ åŸŸåè§„åˆ™

### Phase 3: æ™ºèƒ½åŒ–ï¼ˆå¯é€‰ï¼‰
- æœºå™¨å­¦ä¹ è¯†åˆ«å‚æ•°ç±»å‹
- è‡ªé€‚åº”è§„åˆ™è°ƒæ•´

**å¤§å¸ˆè§‰å¾—è¿™ä¸ªæ–¹æ¡ˆå¦‚ä½•ï¼Ÿå¯ä»¥å¼€å§‹ç¼–ç å—ï¼Ÿ** ğŸ¦