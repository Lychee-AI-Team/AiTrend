#!/usr/bin/env python3
"""
HackerNews ä¿¡æ¯æºæ¨¡å—
ä» HackerNews è·å–çƒ­é—¨æŠ€æœ¯è®¨è®ºå’Œé¡¹ç›®
"""

import os
import re
import requests
from typing import List, Dict, Any
from datetime import datetime, timedelta
from modules.logger import get_logger
from modules.sources.base import BaseSource

logger = get_logger()

class Hackernews(BaseSource):
    """
    HackerNews ä¿¡æ¯æºæ¨¡å—
    
    åŠŸèƒ½ï¼š
    - è·å–çƒ­é—¨å¸–å­ï¼ˆtop stories, best storiesï¼‰
    - è¿‡æ»¤æŠ€æœ¯ç›¸å…³æ ‡ç­¾
    - æå–é«˜èµè¯„è®º
    
    æŒ–æ˜æ ‡å‡†ï¼š
    - åˆ†æ•° > 100
    - è¯„è®ºæ•° > 20
    - é“¾æ¥æŒ‡å‘ GitHub æˆ–äº§å“é¡µ
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.api_base = "https://hacker-news.firebaseio.com/v0"
        self.min_points = config.get('min_points', 100)
        self.min_comments = config.get('min_comments', 20)
        self.max_candidates = config.get('max_candidates', 10)
        self.target_keywords = config.get('keywords', ['AI', 'machine learning', 'open source', 'github', 'developer', 'programming'])
        
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        logger.info(f"Hackernews æ¨¡å—åˆå§‹åŒ–")
        logger.info(f"  - æœ€å°åˆ†æ•°: {self.min_points}")
        logger.info(f"  - æœ€å°è¯„è®º: {self.min_comments}")
    
    def is_enabled(self) -> bool:
        """HackerNews API æ— éœ€è®¤è¯ï¼Œå§‹ç»ˆå¯ç”¨"""
        return True
    
    def discover(self) -> List[Dict[str, Any]]:
        """
        å‘ç°çƒ­é—¨å¸–å­
        
        è¿”å› HN ä¸Šåˆ†æ•°è¾¾æ ‡çš„æŠ€æœ¯ç›¸å…³å¸–å­
        """
        logger.section("ğŸ“¡ ä» HackerNews æŒ–æ˜çƒ­é—¨å¸–å­")
        
        all_candidates = []
        
        # è·å– top stories
        try:
            logger.info("  è·å– Top Stories...")
            top_ids = self._fetch_story_ids('topstories')
            candidates = self._process_stories(top_ids[:30])  # å¤„ç†å‰30ä¸ª
            logger.info(f"    è·å– {len(candidates)} ä¸ªå¸–å­")
            all_candidates.extend(candidates)
        except Exception as e:
            logger.error(f"    è·å–å¤±è´¥: {e}")
        
        # è·å– best stories
        try:
            logger.info("  è·å– Best Stories...")
            best_ids = self._fetch_story_ids('beststories')
            candidates = self._process_stories(best_ids[:30])
            logger.info(f"    è·å– {len(candidates)} ä¸ªå¸–å­")
            all_candidates.extend(candidates)
        except Exception as e:
            logger.error(f"    è·å–å¤±è´¥: {e}")
        
        # å»é‡ï¼ˆæŒ‰ IDï¼‰
        seen_ids = set()
        unique_candidates = []
        for c in all_candidates:
            item_id = c.get('id', '')
            if item_id and item_id not in seen_ids:
                seen_ids.add(item_id)
                unique_candidates.append(c)
        
        # æŒ‰åˆ†æ•°æ’åº
        sorted_candidates = sorted(unique_candidates, key=lambda x: x.get('points', 0), reverse=True)
        
        # é™åˆ¶æ•°é‡
        result = sorted_candidates[:self.max_candidates]
        
        logger.info(f"âœ… æ€»è®¡å‘ç° {len(result)} ä¸ªå€™é€‰å¸–å­")
        
        return result
    
    def _fetch_story_ids(self, story_type: str) -> List[int]:
        """è·å–æ•…äº‹ ID åˆ—è¡¨"""
        url = f"{self.api_base}/{story_type}.json"
        
        response = self.session.get(url, timeout=10)
        response.raise_for_status()
        
        return response.json() or []
    
    def _process_stories(self, story_ids: List[int]) -> List[Dict]:
        """å¤„ç†æ•…äº‹åˆ—è¡¨ï¼Œç­›é€‰æŠ€æœ¯ç›¸å…³å†…å®¹"""
        candidates = []
        
        for story_id in story_ids:
            try:
                story = self._fetch_item(story_id)
                if not story:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ•…äº‹ï¼ˆä¸æ˜¯è¯„è®ºæˆ–jobï¼‰
                if story.get('type') != 'story':
                    continue
                
                points = story.get('score', 0)
                comments = story.get('descendants', 0)
                title = story.get('title', '')
                url = story.get('url', '')
                
                # è¿‡æ»¤æ¡ä»¶
                if points < self.min_points:
                    continue
                
                if comments < self.min_comments:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æŠ€æœ¯ç›¸å…³
                if not self._is_tech_related(title, url):
                    continue
                
                # è·å–é«˜èµè¯„è®º
                top_comments = self._fetch_top_comments(story_id, limit=3)
                
                candidate = {
                    'id': story_id,
                    'name': self._extract_project_name(title, url),
                    'title': title,
                    'url': url or f"https://news.ycombinator.com/item?id={story_id}",
                    'points': points,
                    'comments': comments,
                    'top_comments': top_comments,
                    'hn_url': f"https://news.ycombinator.com/item?id={story_id}",
                    'source_type': 'hackernews',
                    'source_name': 'HackerNews'
                }
                
                candidates.append(candidate)
                
            except Exception as e:
                logger.debug(f"    å¤„ç†æ•…äº‹ {story_id} å¤±è´¥: {e}")
                continue
        
        return candidates
    
    def _fetch_item(self, item_id: int) -> Dict:
        """è·å–å•ä¸ªé¡¹ç›®è¯¦æƒ…"""
        url = f"{self.api_base}/item/{item_id}.json"
        
        response = self.session.get(url, timeout=10)
        response.raise_for_status()
        
        return response.json() or {}
    
    def _is_tech_related(self, title: str, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æŠ€æœ¯ç›¸å…³å†…å®¹"""
        text = f"{title} {url}".lower()
        
        # æ£€æŸ¥å…³é”®è¯
        for keyword in self.target_keywords:
            if keyword.lower() in text:
                return True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ GitHub é“¾æ¥
        if 'github.com' in url:
            return True
        
        return False
    
    def _fetch_top_comments(self, story_id: int, limit: int = 3) -> List[str]:
        """è·å–é«˜èµè¯„è®º - ç®€åŒ–ç‰ˆï¼Œé¿å…è¿‡å¤šç½‘ç»œè¯·æ±‚"""
        # æš‚æ—¶è·³è¿‡è¯„è®ºè·å–ï¼Œé¿å…æ€§èƒ½é—®é¢˜
        # åç»­å¯ä»¥æ·»åŠ ç¼“å­˜æˆ–æ‰¹é‡è·å–ä¼˜åŒ–
        return []
    
    def _extract_project_name(self, title: str, url: str) -> str:
        """ä»æ ‡é¢˜æˆ–URLæå–é¡¹ç›®å"""
        # å°è¯•ä»æ ‡é¢˜æå–
        # æ¨¡å¼: "Show HN: Project Name - description"
        match = re.match(r'Show HN:\s*([^-â€“:]+)', title, re.I)
        if match:
            return match.group(1).strip()[:50]
        
        # æ¨¡å¼: "Project Name: description"
        match = re.match(r'^([^:]+):', title)
        if match and len(match.group(1)) < 50:
            return match.group(1).strip()[:50]
        
        # ä» URL æå–
        if 'github.com' in url:
            parts = url.split('/')
            if len(parts) >= 3:
                return parts[-1][:50] if parts[-1] else parts[-2][:50]
        
        # é»˜è®¤è¿”å›æ ‡é¢˜å‰50å­—
        return title[:50]
    
    def get_details(self, candidate: Dict) -> Dict[str, Any]:
        """è·å–å¸–å­è¯¦ç»†ä¿¡æ¯"""
        return candidate

# æµ‹è¯•
if __name__ == '__main__':
    print("="*60)
    print("HackerNews ä¿¡æ¯æºæ¨¡å—æµ‹è¯•")
    print("="*60)
    
    config = {
        'min_points': 50,
        'min_comments': 10,
        'max_candidates': 5
    }
    
    source = Hackernews(config)
    candidates = source.discover()
    
    print(f"\nå‘ç° {len(candidates)} ä¸ªå€™é€‰å¸–å­:")
    for i, c in enumerate(candidates, 1):
        print(f"\n{i}. {c['name']}")
        print(f"   æ ‡é¢˜: {c['title'][:60]}...")
        print(f"   åˆ†æ•°: {c['points']}, è¯„è®º: {c['comments']}")
        print(f"   URL: {c['url']}")
        if c['top_comments']:
            print(f"   è¯„è®ºé¢„è§ˆ: {c['top_comments'][0][:100]}...")
